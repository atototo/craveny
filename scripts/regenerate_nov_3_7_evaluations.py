"""
11ì›” 3-7ì¼ ModelEvaluation ì¬ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ìƒˆë¡œ ìƒì„±ëœ StockAnalysisSummaryë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  ëª¨ë¸ì˜ í‰ê°€ ë°ì´í„°ë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤.
"""
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from datetime import datetime, date
from backend.db.session import SessionLocal
from backend.services.evaluation_service import EvaluationService
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def run_evaluation_for_date(target_date: date):
    """íŠ¹ì • ë‚ ì§œì˜ í‰ê°€ ì‹¤í–‰"""
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸ“Š {target_date} í‰ê°€ ì‹œì‘")
    logger.info(f"{'='*80}")

    db = SessionLocal()
    try:
        service = EvaluationService(db)

        # í‰ê°€ ëŒ€ìƒ ì¡°íšŒ (í•´ë‹¹ ë‚ ì§œì— ìƒì„±ëœ Investment Report)
        target_datetime = datetime.combine(target_date, datetime.min.time())
        reports = service.get_evaluable_reports(target_datetime)

        if not reports:
            logger.warning(f"âš ï¸ {target_date}: í‰ê°€ ëŒ€ìƒ ì—†ìŒ")
            return 0, 0

        logger.info(f"ğŸ“Š í‰ê°€ ëŒ€ìƒ: {len(reports)}ê°œ ë¦¬í¬íŠ¸")

        success_count = 0
        error_count = 0

        for report in reports:
            try:
                # A/B í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ì¸ ê²½ìš° ë‘ ëª¨ë¸ ëª¨ë‘ í‰ê°€
                if report.custom_data and report.custom_data.get('ab_test_enabled'):
                    # Model A í‰ê°€
                    model_a_data = report.custom_data.get('model_a', {})
                    model_a_id = None

                    # OpenRouter ëª¨ë¸ì—ì„œ ID ì¶”ì¶œ
                    if model_a_data.get('provider') == 'openrouter':
                        # Model AëŠ” ID 2 (Qwen3 Max)
                        model_a_id = 2

                    if model_a_id:
                        try:
                            evaluation_a = service.evaluate_report(report, model_id=model_a_id)
                            if evaluation_a:
                                success_count += 1
                                logger.info(
                                    f"  âœ… Model A (ID={model_a_id}) í‰ê°€ ì™„ë£Œ: {report.stock_code}, "
                                    f"score={evaluation_a.final_score:.1f}"
                                )
                        except Exception as e:
                            error_count += 1
                            logger.error(f"  âŒ Model A í‰ê°€ ì‹¤íŒ¨: {report.stock_code}, {e}")

                    # Model B í‰ê°€
                    model_b_data = report.custom_data.get('model_b', {})
                    model_b_id = None

                    if model_b_data.get('provider') == 'openrouter':
                        # Model BëŠ” ID 5 (DeepSeek V3.2)
                        model_b_id = 5

                    if model_b_id:
                        try:
                            evaluation_b = service.evaluate_report(report, model_id=model_b_id)
                            if evaluation_b:
                                success_count += 1
                                logger.info(
                                    f"  âœ… Model B (ID={model_b_id}) í‰ê°€ ì™„ë£Œ: {report.stock_code}, "
                                    f"score={evaluation_b.final_score:.1f}"
                                )
                        except Exception as e:
                            error_count += 1
                            logger.error(f"  âŒ Model B í‰ê°€ ì‹¤íŒ¨: {report.stock_code}, {e}")
                else:
                    # ì¼ë°˜ ë¦¬í¬íŠ¸ëŠ” ê¸°ë³¸ ëª¨ë¸ë¡œ í‰ê°€ (ID 1)
                    evaluation = service.evaluate_report(report, model_id=1)
                    if evaluation:
                        success_count += 1
                        logger.info(
                            f"  âœ… í‰ê°€ ì™„ë£Œ: {report.stock_code}, "
                            f"score={evaluation.final_score:.1f}"
                        )
                    else:
                        error_count += 1

            except Exception as e:
                error_count += 1
                logger.error(f"  âŒ í‰ê°€ ì‹¤íŒ¨: {report.stock_code}, {e}")

        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸ‰ {target_date} í‰ê°€ ì™„ë£Œ")
        logger.info(f"  ì„±ê³µ: {success_count}ê°œ, ì‹¤íŒ¨: {error_count}ê°œ")
        logger.info(f"{'='*80}\n")

        return success_count, error_count

    except Exception as e:
        logger.error(f"\nâŒ ë‚ ì§œ ì²˜ë¦¬ ì‹¤íŒ¨: {target_date}, {e}")
        import traceback
        traceback.print_exc()
        return 0, 0
    finally:
        db.close()


def regenerate_all_evaluations():
    """11ì›” 3-7ì¼ ëª¨ë“  í‰ê°€ ì¬ìƒì„±"""
    logger.info("=" * 80)
    logger.info("ğŸ”„ 11ì›” 3-7ì¼ ModelEvaluation ì¬ìƒì„± ì‹œì‘")
    logger.info("=" * 80)

    # 11ì›” 3-7ì¼
    dates = [
        date(2025, 11, 3),
        date(2025, 11, 4),
        date(2025, 11, 5),
        date(2025, 11, 6),
        date(2025, 11, 7),
    ]

    total_success = 0
    total_error = 0

    for target_date in dates:
        success, error = run_evaluation_for_date(target_date)
        total_success += success
        total_error += error

    logger.info("\n" + "=" * 80)
    logger.info("ğŸ¯ ì „ì²´ ì¬ìƒì„± ì™„ë£Œ ìš”ì•½")
    logger.info("=" * 80)
    logger.info(f"  ì´ ì„±ê³µ: {total_success}ê°œ")
    logger.info(f"  ì´ ì‹¤íŒ¨: {total_error}ê°œ")
    if total_success + total_error > 0:
        logger.info(f"  ì„±ê³µë¥ : {total_success / (total_success + total_error) * 100:.1f}%")
    logger.info("=" * 80)
    logger.info("\nâœ… 11ì›” 3-7ì¼ ModelEvaluation ì¬ìƒì„± ì™„ë£Œ!")


if __name__ == "__main__":
    print("\nğŸ“¢ 11ì›” 3-7ì¼ ëª¨ë“  ModelEvaluationì„ ì¬ìƒì„±í•©ë‹ˆë‹¤.")
    print("   (StockAnalysisSummary ê¸°ë°˜)")
    response = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")

    if response.lower() == "yes":
        regenerate_all_evaluations()
    else:
        print("âŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
