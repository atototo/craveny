"""
KIS API ê³¼ê±° 90ì¼ ë°ì´í„° ë°±í•„ ìŠ¤í¬ë¦½íŠ¸

Usage:
    uv run python scripts/backfill_kis_daily_prices.py [--days 90]
"""
import asyncio
import logging
import argparse
from datetime import datetime

from backend.crawlers.kis_daily_crawler import get_kis_daily_crawler
from backend.db.session import SessionLocal
from backend.db.models.stock import Stock


# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def backfill_kis_data(days: int = 90):
    """
    KIS API ê³¼ê±° ë°ì´í„° ë°±í•„

    Args:
        days: ë°±í•„ ê¸°ê°„ (ì¼)
    """
    logger.info("=" * 80)
    logger.info(f"ğŸš€ KIS API ê³¼ê±° {days}ì¼ ë°ì´í„° ë°±í•„ ì‹œì‘")
    logger.info("=" * 80)

    db = SessionLocal()

    try:
        # í™œì„± ì¢…ëª© ìˆ˜ í™•ì¸
        active_stocks = db.query(Stock).filter(Stock.is_active == True).count()
        logger.info(f"ğŸ“Š í™œì„± ì¢…ëª© ìˆ˜: {active_stocks}ê°œ")
        logger.info(f"ğŸ“… ë°±í•„ ê¸°ê°„: {days}ì¼")

        expected_records = active_stocks * days * 0.7  # ì£¼ë§ ì œì™¸
        logger.info(f"ğŸ¯ ì˜ˆìƒ ìˆ˜ì§‘ ê±´ìˆ˜: ì•½ {int(expected_records):,}ê±´")
        logger.info("")

        # ë°±í•„ ì‹¤í–‰
        crawler = get_kis_daily_crawler()
        result = await crawler.backfill_historical_data(days=days)

        # ê²°ê³¼ ì¶œë ¥
        logger.info("")
        logger.info("=" * 80)
        logger.info("ğŸ“Š ë°±í•„ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 80)
        logger.info(f"ì´ ì¢…ëª© ìˆ˜: {result['total_stocks']}ê°œ")
        logger.info(f"ì„±ê³µ: {result['success_count']}ê°œ")
        logger.info(f"ì‹¤íŒ¨: {result['failed_count']}ê°œ")
        logger.info(f"ì„±ê³µë¥ : {result['success_rate']:.1f}%")
        logger.info(f"ì´ ì €ì¥ ê±´ìˆ˜: {result['total_saved']:,}ê±´")
        logger.info("")

        # ì‹¤íŒ¨í•œ ì¢…ëª© ì²´í¬ (ìˆë‹¤ë©´)
        failed_stocks = [r for r in result['results'] if r['status'] != 'success']
        if failed_stocks:
            logger.warning(f"âš ï¸  ì‹¤íŒ¨í•œ ì¢…ëª© ({len(failed_stocks)}ê°œ):")
            for r in failed_stocks[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                logger.warning(f"  - {r['stock_code']}: {r.get('error', 'Unknown error')}")

            if len(failed_stocks) > 10:
                logger.warning(f"  ... ì™¸ {len(failed_stocks) - 10}ê°œ")

        logger.info("=" * 80)

        # ì„±ê³µ ê¸°ì¤€ í™•ì¸
        if result['success_rate'] >= 99.0:
            logger.info("âœ… ë°±í•„ ì™„ë£Œ! (ì„±ê³µë¥  â‰¥99%)")
            return True
        else:
            logger.warning(f"âš ï¸  ì„±ê³µë¥  {result['success_rate']:.1f}% - ëª©í‘œ 99% ë¯¸ë‹¬")
            return False

    except Exception as e:
        logger.error(f"âŒ ë°±í•„ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
        return False

    finally:
        db.close()


async def verify_backfill(days: int = 90):
    """
    ë°±í•„ ê²°ê³¼ ê²€ì¦

    Args:
        days: ë°±í•„ ê¸°ê°„ (ì¼)
    """
    logger.info("")
    logger.info("=" * 80)
    logger.info("ğŸ” ë°±í•„ ê²°ê³¼ ê²€ì¦")
    logger.info("=" * 80)

    from datetime import timedelta
    from sqlalchemy import and_, func
    from backend.db.models.stock import StockPrice

    db = SessionLocal()

    try:
        # KIS ì†ŒìŠ¤ ë°ì´í„° í†µê³„
        start_date = datetime.now() - timedelta(days=days)

        total_records = db.query(func.count(StockPrice.id)).filter(
            and_(
                StockPrice.source == "kis",
                StockPrice.date >= start_date
            )
        ).scalar()

        unique_stocks = db.query(func.count(func.distinct(StockPrice.stock_code))).filter(
            and_(
                StockPrice.source == "kis",
                StockPrice.date >= start_date
            )
        ).scalar()

        logger.info(f"ğŸ“Š DB ì €ì¥ í˜„í™©:")
        logger.info(f"  ì´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê±´")
        logger.info(f"  ì¢…ëª© ìˆ˜: {unique_stocks}ê°œ")
        logger.info(f"  ì¢…ëª©ë‹¹ í‰ê· : {total_records / unique_stocks:.1f}ê±´" if unique_stocks > 0 else "  ì¢…ëª©ë‹¹ í‰ê· : 0ê±´")

        # ìµœê·¼ ë°ì´í„° ìƒ˜í”Œ í™•ì¸
        latest_prices = db.query(StockPrice).filter(
            StockPrice.source == "kis"
        ).order_by(StockPrice.date.desc()).limit(5).all()

        logger.info(f"\nìµœê·¼ ë°ì´í„° ìƒ˜í”Œ (KIS ì†ŒìŠ¤):")
        for price in latest_prices:
            logger.info(
                f"  {price.stock_code} - {price.date.date()}: "
                f"ì¢…ê°€ {price.close:,}ì›, ê±°ë˜ëŸ‰ {price.volume:,}ì£¼"
            )

        logger.info("=" * 80)

        return total_records > 0

    except Exception as e:
        logger.error(f"âŒ ê²€ì¦ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)
        return False

    finally:
        db.close()


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    parser = argparse.ArgumentParser(description="KIS API ê³¼ê±° ë°ì´í„° ë°±í•„")
    parser.add_argument(
        "--days",
        type=int,
        default=90,
        help="ë°±í•„ ê¸°ê°„ (ì¼, ê¸°ë³¸: 90)"
    )
    args = parser.parse_args()

    start_time = datetime.now()

    try:
        # ë°±í•„ ì‹¤í–‰
        success = await backfill_kis_data(days=args.days)

        # ê²€ì¦
        if success:
            verified = await verify_backfill(days=args.days)

            if verified:
                logger.info("\nâœ… ë°±í•„ ë° ê²€ì¦ ì™„ë£Œ!")
            else:
                logger.warning("\nâš ï¸  ë°±í•„ ì™„ë£Œí–ˆìœ¼ë‚˜ ê²€ì¦ ì‹¤íŒ¨")
        else:
            logger.error("\nâŒ ë°±í•„ ì‹¤íŒ¨")

        # ì†Œìš” ì‹œê°„ ê³„ì‚°
        elapsed = datetime.now() - start_time
        logger.info(f"\nâ±ï¸  ì†Œìš” ì‹œê°„: {elapsed.total_seconds():.1f}ì´ˆ")

    except Exception as e:
        logger.error(f"\nâŒ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(main())
