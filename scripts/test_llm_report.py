"""
LLM ê¸°ë°˜ íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.db.session import SessionLocal
from backend.services.stock_analysis_service import update_stock_analysis_summary, get_stock_analysis_summary
import asyncio
import json


async def test_llm_report():
    """LLM ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    db = SessionLocal()

    try:
        # í…ŒìŠ¤íŠ¸ ì¢…ëª©: ì‚¼ì„±ì „ì
        stock_code = "005930"

        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì¢…ëª© {stock_code}ì— ëŒ€í•œ LLM íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸")
        print(f"{'='*60}\n")

        # 1. ê¸°ì¡´ ìºì‹œ ì¡°íšŒ
        print("1ï¸âƒ£  ê¸°ì¡´ ìºì‹œ ì¡°íšŒ...")
        existing_summary = get_stock_analysis_summary(stock_code, db)

        if existing_summary:
            print("âœ… ê¸°ì¡´ ìºì‹œ ë°œê²¬:")
            print(f"   - ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {existing_summary['meta']['last_updated']}")
            print(f"   - ë¶„ì„ ì˜ˆì¸¡ ê±´ìˆ˜: {existing_summary['meta']['based_on_prediction_count']}")
        else:
            print("âŒ ê¸°ì¡´ ìºì‹œ ì—†ìŒ\n")

        # 2. LLM ë¦¬í¬íŠ¸ ìƒì„± (ê°•ì œ ì—…ë°ì´íŠ¸)
        print("\n2ï¸âƒ£  LLM ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        summary_obj = await update_stock_analysis_summary(stock_code, db, force_update=True)

        if not summary_obj:
            print("âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨!")
            return

        print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!\n")

        # 3. ìƒì„±ëœ ë¦¬í¬íŠ¸ ì¡°íšŒ
        print("3ï¸âƒ£  ìƒì„±ëœ ë¦¬í¬íŠ¸ ë‚´ìš©:")
        print(f"{'='*60}\n")

        new_summary = get_stock_analysis_summary(stock_code, db)

        if new_summary:
            print(f"ğŸ“ˆ ì¢…í•© ì˜ê²¬:")
            print(f"   {new_summary['overall_summary']}\n")

            if new_summary['short_term_scenario']:
                print(f"ğŸ”¹ ë‹¨ê¸° ì‹œë‚˜ë¦¬ì˜¤ (1-3ì¼):")
                print(f"   {new_summary['short_term_scenario']}\n")

            if new_summary['medium_term_scenario']:
                print(f"ğŸ”¸ ì¤‘ê¸° ì‹œë‚˜ë¦¬ì˜¤ (5-10ì¼):")
                print(f"   {new_summary['medium_term_scenario']}\n")

            if new_summary['long_term_scenario']:
                print(f"ğŸ”¶ ì¥ê¸° ì‹œë‚˜ë¦¬ì˜¤ (20ì¼+):")
                print(f"   {new_summary['long_term_scenario']}\n")

            if new_summary['risk_factors']:
                print(f"âš ï¸  ë¦¬ìŠ¤í¬ ìš”ì¸:")
                for i, risk in enumerate(new_summary['risk_factors'], 1):
                    print(f"   {i}. {risk}")
                print()

            if new_summary['opportunity_factors']:
                print(f"ğŸ’¡ ê¸°íšŒ ìš”ì¸:")
                for i, opp in enumerate(new_summary['opportunity_factors'], 1):
                    print(f"   {i}. {opp}")
                print()

            if new_summary['recommendation']:
                print(f"ğŸ¯ ìµœì¢… ì¶”ì²œ:")
                print(f"   {new_summary['recommendation']}\n")

            print(f"{'='*60}")
            print(f"ğŸ“Š í†µê³„:")
            stats = new_summary['statistics']
            print(f"   - ì´ ì˜ˆì¸¡: {stats['total_predictions']}ê±´")
            print(f"   - ìƒìŠ¹/í•˜ë½/ë³´í•©: {stats['up_count']}/{stats['down_count']}/{stats['hold_count']}")
            print(f"   - í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']}%")
            print(f"{'='*60}\n")

            # JSON í˜•ì‹ìœ¼ë¡œë„ ì¶œë ¥
            print("ğŸ“„ JSON ì‘ë‹µ:")
            print(json.dumps(new_summary, ensure_ascii=False, indent=2))

    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()


if __name__ == "__main__":
    asyncio.run(test_llm_report())
