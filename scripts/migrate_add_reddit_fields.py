"""
ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜: Reddit í†µí•©ì„ ìœ„í•œ í•„ë“œ ì¶”ê°€

NewsArticle í…Œì´ë¸”ì— ë‹¤ìŒ í•„ë“œë“¤ì„ ì¶”ê°€:
- content_type: ì½˜í…ì¸  íƒ€ì… (news, reddit, twitter ë“±)
- url: ì›ë³¸ URL
- author: ì‘ì„±ì
- upvotes: Reddit upvote ìˆ˜
- num_comments: Reddit ëŒ“ê¸€ ìˆ˜
- subreddit: Subreddit ì´ë¦„
- metadata: JSON ë©”íƒ€ë°ì´í„°
"""
import logging
from sqlalchemy import text
from backend.db.session import SessionLocal, engine

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def upgrade():
    """Reddit ì§€ì› í•„ë“œ ì¶”ê°€"""
    db = SessionLocal()

    try:
        logger.info("=" * 60)
        logger.info("Reddit í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
        logger.info("=" * 60)

        # 1. content_type enum íƒ€ì… ìƒì„±
        logger.info("1. ContentType enum ìƒì„± ì¤‘...")
        db.execute(text("""
            DO $$ BEGIN
                CREATE TYPE contenttype AS ENUM ('news', 'reddit', 'twitter', 'telegram');
            EXCEPTION
                WHEN duplicate_object THEN null;
            END $$;
        """))
        logger.info("âœ… ContentType enum ìƒì„± ì™„ë£Œ")

        # 2. content_type ì»¬ëŸ¼ ì¶”ê°€
        logger.info("2. content_type ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS content_type contenttype NOT NULL DEFAULT 'news';
        """))
        logger.info("âœ… content_type ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 3. url ì»¬ëŸ¼ ì¶”ê°€
        logger.info("3. url ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS url VARCHAR(1000);
        """))
        logger.info("âœ… url ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 4. author ì»¬ëŸ¼ ì¶”ê°€
        logger.info("4. author ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS author VARCHAR(200);
        """))
        logger.info("âœ… author ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 5. upvotes ì»¬ëŸ¼ ì¶”ê°€
        logger.info("5. upvotes ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS upvotes INTEGER;
        """))
        logger.info("âœ… upvotes ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 6. num_comments ì»¬ëŸ¼ ì¶”ê°€
        logger.info("6. num_comments ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS num_comments INTEGER;
        """))
        logger.info("âœ… num_comments ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 7. subreddit ì»¬ëŸ¼ ì¶”ê°€
        logger.info("7. subreddit ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS subreddit VARCHAR(100);
        """))
        logger.info("âœ… subreddit ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 8. metadata ì»¬ëŸ¼ ì¶”ê°€ (JSONB)
        logger.info("8. metadata ì»¬ëŸ¼ ì¶”ê°€ ì¤‘...")
        db.execute(text("""
            ALTER TABLE news_articles
            ADD COLUMN IF NOT EXISTS metadata JSONB;
        """))
        logger.info("âœ… metadata ì»¬ëŸ¼ ì¶”ê°€ ì™„ë£Œ")

        # 9. ì¸ë±ìŠ¤ ìƒì„±
        logger.info("9. ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")

        # content_type ì¸ë±ìŠ¤
        db.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_news_articles_content_type
            ON news_articles(content_type);
        """))
        logger.info("âœ… idx_news_articles_content_type ìƒì„± ì™„ë£Œ")

        # subreddit ì¸ë±ìŠ¤
        db.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_news_articles_subreddit
            ON news_articles(subreddit);
        """))
        logger.info("âœ… idx_news_articles_subreddit ìƒì„± ì™„ë£Œ")

        # source + content_type ë³µí•© ì¸ë±ìŠ¤
        db.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_news_articles_source_type
            ON news_articles(source, content_type);
        """))
        logger.info("âœ… idx_news_articles_source_type ìƒì„± ì™„ë£Œ")

        # 10. ê¸°ì¡´ ë°ì´í„° backfill (content_typeì„ 'news'ë¡œ ì„¤ì •)
        logger.info("10. ê¸°ì¡´ ë°ì´í„° backfill ì¤‘...")
        result = db.execute(text("""
            UPDATE news_articles
            SET content_type = 'news'
            WHERE content_type IS NULL;
        """))
        logger.info(f"âœ… {result.rowcount}ê±´ì˜ ê¸°ì¡´ ë°ì´í„°ë¥¼ 'news'ë¡œ ì„¤ì • ì™„ë£Œ")

        db.commit()

        logger.info("=" * 60)
        logger.info("âœ… Reddit í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        logger.info("=" * 60)

        # ê²°ê³¼ í™•ì¸
        logger.info("\nğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼ í™•ì¸:")
        result = db.execute(text("""
            SELECT
                content_type,
                COUNT(*) as count
            FROM news_articles
            GROUP BY content_type;
        """))

        for row in result:
            logger.info(f"  - {row.content_type}: {row.count}ê±´")

    except Exception as e:
        db.rollback()
        logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}", exc_info=True)
        raise
    finally:
        db.close()


def downgrade():
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°± (Reddit í•„ë“œ ì œê±°)"""
    db = SessionLocal()

    try:
        logger.info("=" * 60)
        logger.info("Reddit í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°± ì‹œì‘")
        logger.info("=" * 60)

        # ì¸ë±ìŠ¤ ì‚­ì œ
        logger.info("1. ì¸ë±ìŠ¤ ì‚­ì œ ì¤‘...")
        db.execute(text("DROP INDEX IF EXISTS idx_news_articles_source_type;"))
        db.execute(text("DROP INDEX IF EXISTS idx_news_articles_subreddit;"))
        db.execute(text("DROP INDEX IF EXISTS idx_news_articles_content_type;"))
        logger.info("âœ… ì¸ë±ìŠ¤ ì‚­ì œ ì™„ë£Œ")

        # ì»¬ëŸ¼ ì‚­ì œ
        logger.info("2. ì»¬ëŸ¼ ì‚­ì œ ì¤‘...")
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS metadata;"))
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS subreddit;"))
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS num_comments;"))
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS upvotes;"))
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS author;"))
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS url;"))
        db.execute(text("ALTER TABLE news_articles DROP COLUMN IF EXISTS content_type;"))
        logger.info("âœ… ì»¬ëŸ¼ ì‚­ì œ ì™„ë£Œ")

        # enum íƒ€ì… ì‚­ì œ
        logger.info("3. ContentType enum ì‚­ì œ ì¤‘...")
        db.execute(text("DROP TYPE IF EXISTS contenttype;"))
        logger.info("âœ… ContentType enum ì‚­ì œ ì™„ë£Œ")

        db.commit()

        logger.info("=" * 60)
        logger.info("âœ… Reddit í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°± ì™„ë£Œ!")
        logger.info("=" * 60)

    except Exception as e:
        db.rollback()
        logger.error(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {e}", exc_info=True)
        raise
    finally:
        db.close()


def check_migration_status():
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸"""
    db = SessionLocal()

    try:
        logger.info("=" * 60)
        logger.info("ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸")
        logger.info("=" * 60)

        # ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        result = db.execute(text("""
            SELECT column_name, data_type
            FROM information_schema.columns
            WHERE table_name = 'news_articles'
            AND column_name IN (
                'content_type', 'url', 'author', 'upvotes',
                'num_comments', 'subreddit', 'metadata'
            )
            ORDER BY column_name;
        """))

        columns = list(result)

        if columns:
            logger.info("\nâœ… Reddit í†µí•© í•„ë“œê°€ ì¡´ì¬í•©ë‹ˆë‹¤:")
            for col in columns:
                logger.info(f"  - {col.column_name}: {col.data_type}")
        else:
            logger.info("\nâš ï¸ Reddit í†µí•© í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

        # ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        result = db.execute(text("""
            SELECT indexname
            FROM pg_indexes
            WHERE tablename = 'news_articles'
            AND indexname LIKE '%content_type%' OR indexname LIKE '%subreddit%';
        """))

        indexes = list(result)

        if indexes:
            logger.info("\nâœ… Reddit ê´€ë ¨ ì¸ë±ìŠ¤:")
            for idx in indexes:
                logger.info(f"  - {idx.indexname}")

        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}", exc_info=True)
    finally:
        db.close()


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•:")
        print("  python scripts/migrate_add_reddit_fields.py upgrade   # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰")
        print("  python scripts/migrate_add_reddit_fields.py downgrade # ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°±")
        print("  python scripts/migrate_add_reddit_fields.py status    # ìƒíƒœ í™•ì¸")
        sys.exit(1)

    command = sys.argv[1]

    if command == "upgrade":
        upgrade()
    elif command == "downgrade":
        # ë¡¤ë°± í™•ì¸
        response = input("âš ï¸ ì •ë§ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ë¡¤ë°±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
        if response.lower() == "yes":
            downgrade()
        else:
            print("ë¡¤ë°±ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif command == "status":
        check_migration_status()
    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}")
        sys.exit(1)
