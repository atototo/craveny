"""
í‰ê°€ ê²°ê³¼ ê²€ì¦
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sqlalchemy import func
from backend.db.session import SessionLocal
from backend.db.models.model_evaluation import ModelEvaluation
from backend.db.models.evaluation_history import EvaluationHistory
from backend.db.models.daily_performance import DailyModelPerformance
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def verify_evaluation_results():
    """í‰ê°€ ê²°ê³¼ ê²€ì¦"""
    db = SessionLocal()
    try:
        logger.info("=" * 80)
        logger.info("ğŸ“Š í‰ê°€ ê²°ê³¼ ê²€ì¦")
        logger.info("=" * 80)

        # 1. ModelEvaluation ê²°ê³¼ í™•ì¸
        logger.info("\n1ï¸âƒ£ ModelEvaluation í…Œì´ë¸”")
        total_evaluations = db.query(ModelEvaluation).count()
        logger.info(f"  ì´ í‰ê°€ ê±´ìˆ˜: {total_evaluations}ê±´")

        # ë‚ ì§œë³„ í‰ê°€ ê±´ìˆ˜
        date_counts = db.query(
            func.date(ModelEvaluation.predicted_at).label('date'),
            func.count(ModelEvaluation.id).label('count'),
            func.avg(ModelEvaluation.final_score).label('avg_score')
        ).group_by(
            func.date(ModelEvaluation.predicted_at)
        ).order_by('date').all()

        logger.info("\n  ğŸ“… ë‚ ì§œë³„ í‰ê°€ ê²°ê³¼:")
        for date, count, avg_score in date_counts:
            logger.info(
                f"    {date}: {count}ê±´, "
                f"í‰ê·  ì ìˆ˜ {avg_score:.1f}"
            )

        # 2. DailyModelPerformance ê²°ê³¼ í™•ì¸
        logger.info("\n2ï¸âƒ£ DailyModelPerformance í…Œì´ë¸”")
        daily_perfs = db.query(DailyModelPerformance).order_by(
            DailyModelPerformance.date
        ).all()

        logger.info(f"  ì´ ì§‘ê³„ ë ˆì½”ë“œ: {len(daily_perfs)}ê±´")

        if daily_perfs:
            logger.info("\n  ğŸ“ˆ ì¼ë³„ ì„±ê³¼ ì§‘ê³„:")
            for perf in daily_perfs:
                logger.info(
                    f"    {perf.date}: "
                    f"í‰ê°€ {perf.evaluated_count}ê±´, "
                    f"í‰ê·  ì ìˆ˜ {perf.avg_final_score:.1f}, "
                    f"ëª©í‘œê°€ ë‹¬ì„±ë¥  {perf.target_achieved_rate:.1f}%"
                )

        # 3. ìƒ˜í”Œ í‰ê°€ ë‚´ì—­
        logger.info("\n3ï¸âƒ£ ìƒ˜í”Œ í‰ê°€ ë‚´ì—­ (ê° ë‚ ì§œë³„ 3ê±´)")
        for date, _, _ in date_counts[:3]:
            evals = db.query(ModelEvaluation).filter(
                func.date(ModelEvaluation.predicted_at) == date
            ).limit(3).all()

            logger.info(f"\n  ğŸ“… {date}:")
            for eval in evals:
                logger.info(
                    f"    {eval.stock_code}: "
                    f"ì ìˆ˜={eval.final_score:.1f}, "
                    f"ëª©í‘œê°€ {'ë‹¬ì„±' if eval.target_achieved else 'ë¯¸ë‹¬ì„±'}, "
                    f"ì†ì ˆ {'ì´íƒˆ' if eval.support_breached else 'ì•ˆì „'}"
                )

        logger.info("\n" + "=" * 80)
        logger.info("âœ… í‰ê°€ ê²°ê³¼ ê²€ì¦ ì™„ë£Œ!")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"âŒ ê²€ì¦ ì‹¤íŒ¨: {e}", exc_info=True)
    finally:
        db.close()


if __name__ == "__main__":
    verify_evaluation_results()
