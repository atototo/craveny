"""
ìë™ ì•Œë¦¼ ëª¨ë“ˆ

ìƒˆë¡œìš´ ë‰´ìŠ¤ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
"""
import logging
from datetime import datetime, timedelta
from typing import List
from sqlalchemy.orm import Session

from backend.db.models.news import NewsArticle
from backend.llm.vector_search import get_vector_search
from backend.llm.predictor import get_predictor
from backend.notifications.telegram import get_telegram_notifier
from backend.utils.embedding_deduplicator import get_embedding_deduplicator
from backend.config import settings


logger = logging.getLogger(__name__)


def process_new_news_notifications(
    db: Session,
    lookback_minutes: int = 15,
) -> dict:
    """
    ìµœê·¼ì— ì €ì¥ëœ ë‰´ìŠ¤ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.

    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        lookback_minutes: ì¡°íšŒí•  ê³¼ê±° ì‹œê°„ (ë¶„ ë‹¨ìœ„)

    Returns:
        ì²˜ë¦¬ í†µê³„ {processed, success, failed}
    """
    try:
        # ìµœê·¼ Në¶„ ì´ë‚´ ì €ì¥ëœ ë‰´ìŠ¤ ì¡°íšŒ (ì¢…ëª© ì½”ë“œê°€ ìˆëŠ” ê²ƒë§Œ)
        cutoff_time = datetime.utcnow() - timedelta(minutes=lookback_minutes)

        recent_news = (
            db.query(NewsArticle)
            .filter(
                NewsArticle.created_at >= cutoff_time,
                NewsArticle.stock_code.isnot(None),
                NewsArticle.notified_at.is_(None),  # ì•„ì§ ì•Œë¦¼ì„ ë³´ë‚´ì§€ ì•Šì€ ë‰´ìŠ¤ë§Œ
            )
            .order_by(NewsArticle.created_at.desc())
            .limit(10)  # ìµœëŒ€ 10ê±´ë§Œ ì²˜ë¦¬
            .all()
        )

        if not recent_news:
            logger.debug(f"ìµœê·¼ {lookback_minutes}ë¶„ ì´ë‚´ ìƒˆ ë‰´ìŠ¤ ì—†ìŒ")
            return {"processed": 0, "success": 0, "failed": 0}

        logger.info(
            f"ğŸ”” ìë™ ì•Œë¦¼ ì²˜ë¦¬: ìµœê·¼ {lookback_minutes}ë¶„ ì´ë‚´ {len(recent_news)}ê±´ ë°œê²¬"
        )

        vector_search = get_vector_search()
        predictor = get_predictor()
        notifier = get_telegram_notifier()
        embedding_deduplicator = get_embedding_deduplicator()

        success_count = 0
        failed_count = 0
        skipped_count = 0

        for news in recent_news:
            try:
                logger.info(f"ì²˜ë¦¬ ì¤‘: {news.title[:50]}... (ì¢…ëª©: {news.stock_code})")

                # 0. ì„ë² ë”© ê¸°ë°˜ ì•Œë¦¼ ì¤‘ë³µ ê²€ì‚¬
                news_text = f"{news.title}\n{news.content}"
                should_skip, similar_id, similarity = embedding_deduplicator.should_skip_notification(
                    news_text=news_text,
                    stock_code=news.stock_code,
                    db=db,
                    notification_lookback_hours=4,
                )

                if should_skip:
                    logger.info(
                        f"ğŸ”• ìœ ì‚¬ ë‰´ìŠ¤ ì•Œë¦¼ ì´ë ¥ ì¡´ì¬ (ìœ ì‚¬ë„={similarity:.3f}) "
                        f"â†’ ì•Œë¦¼ skip (ë‰´ìŠ¤ ID={news.id}, ìœ ì‚¬ ë‰´ìŠ¤ ID={similar_id})"
                    )
                    # notified_at ì—…ë°ì´íŠ¸ (ì•Œë¦¼ skipí–ˆì§€ë§Œ ì²˜ë¦¬ëŠ” ì™„ë£Œ)
                    news.notified_at = datetime.utcnow()
                    db.commit()
                    skipped_count += 1
                    continue

                # 1. ìœ ì‚¬ ë‰´ìŠ¤ ê²€ìƒ‰
                similar_news = vector_search.get_news_with_price_changes(
                    news_text=news_text,
                    stock_code=news.stock_code,
                    db=db,
                    top_k=5,
                    similarity_threshold=0.5,
                )

                # 2. ì˜ˆì¸¡ ìˆ˜í–‰
                current_news_data = {
                    "title": news.title,
                    "content": news.content,
                    "stock_code": news.stock_code,
                }

                # ë©€í‹°ëª¨ë¸ ì˜ˆì¸¡: ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìƒì„±
                all_predictions = predictor.predict_all_models(
                    current_news=current_news_data,
                    similar_news=similar_news,
                    news_id=news.id,
                )

                # A/B ì„¤ì •ì— ë”°ë¼ í‘œì‹œí•  ë‘ ëª¨ë¸ ì˜ˆì¸¡ ì¡°íšŒ
                prediction = predictor.get_ab_predictions(news_id=news.id)

                # 3. í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡
                if notifier.send_prediction(
                    news_title=news.title,
                    stock_code=news.stock_code,
                    prediction=prediction,
                ):
                    # ì•Œë¦¼ ì „ì†¡ ì„±ê³µ ì‹œ notified_at ì—…ë°ì´íŠ¸
                    news.notified_at = datetime.utcnow()
                    db.commit()

                    success_count += 1
                    comp = prediction.get("comparison", {})
                    logger.info(
                        f"âœ… A/B ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {news.title[:30]}... "
                        f"(ëª¨ë¸ {len(all_predictions)}ê°œ ì˜ˆì¸¡ ì™„ë£Œ, A/B ì¼ì¹˜: {comp.get('agreement')}, ì°¨ì´: {comp.get('confidence_diff')}%)"
                    )
                else:
                    failed_count += 1
                    logger.warning(f"âš ï¸  ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {news.title[:30]}...")

            except Exception as e:
                failed_count += 1
                logger.error(f"âŒ ë‰´ìŠ¤ ì²˜ë¦¬ ì‹¤íŒ¨ (ID={news.id}): {e}", exc_info=True)

        logger.info(
            f"ğŸ“Š ìë™ ì•Œë¦¼ ì™„ë£Œ: ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {failed_count}ê±´, skip {skipped_count}ê±´"
        )

        return {
            "processed": len(recent_news),
            "success": success_count,
            "failed": failed_count,
            "skipped": skipped_count,
        }

    except Exception as e:
        logger.error(f"âŒ ìë™ ì•Œë¦¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {"processed": 0, "success": 0, "failed": 0}
