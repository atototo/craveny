"""
í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬

APSchedulerë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ê¸°ì ìœ¼ë¡œ ë‰´ìŠ¤ ë° ì£¼ê°€ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
"""
import logging
import asyncio
from typing import Optional

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger

from backend.crawlers.naver_crawler import NaverNewsCrawler
from backend.crawlers.hankyung_crawler import HankyungNewsCrawler
from backend.crawlers.maeil_crawler import MaeilNewsCrawler
from backend.crawlers.naver_search_crawler import NaverNewsSearchCrawler
from backend.crawlers.dart_crawler import DartCrawler
from backend.crawlers.news_saver import NewsSaver
from backend.crawlers.kis_daily_crawler import get_kis_daily_crawler
from backend.crawlers.kis_minute_collector import run_minute_collector
from backend.crawlers.kis_market_data_collector import (
    OrderbookCollector,
    CurrentPriceCollector,
    InvestorTradingCollector,
    StockInfoCollector,
    SectorIndexCollector,
)
from backend.crawlers.news_stock_matcher import run_daily_matching
from backend.llm.embedder import run_daily_embedding
from backend.utils.market_time import is_market_open
from backend.db.session import SessionLocal
from backend.db.models.stock import Stock
from backend.notifications.auto_notify import process_new_news_notifications


logger = logging.getLogger(__name__)


class CrawlerScheduler:
    """í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤"""

    def __init__(
        self, news_interval_minutes: int = 10, stock_interval_minutes: int = 1
    ):
        """
        Args:
            news_interval_minutes: ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰ ê°„ê²© (ë¶„ ë‹¨ìœ„)
            stock_interval_minutes: ì£¼ê°€ ìˆ˜ì§‘ ì‹¤í–‰ ê°„ê²© (ë¶„ ë‹¨ìœ„)
        """
        self.news_interval_minutes = news_interval_minutes
        self.stock_interval_minutes = stock_interval_minutes
        self.scheduler: Optional[BackgroundScheduler] = None
        self.is_running = False

        # ë‰´ìŠ¤ í¬ë¡¤ë§ í†µê³„
        self.news_total_crawls = 0
        self.news_total_saved = 0
        self.news_total_skipped = 0
        self.news_total_errors = 0

        # ì£¼ê°€ ìˆ˜ì§‘ í†µê³„
        self.stock_total_crawls = 0
        self.stock_total_stocks = 0
        self.stock_total_saved = 0
        self.stock_total_errors = 0

        # ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­ í†µê³„
        self.matching_total_runs = 0
        self.matching_total_success = 0
        self.matching_total_fail = 0

        # ë‰´ìŠ¤ ì„ë² ë”© í†µê³„
        self.embedding_total_runs = 0
        self.embedding_total_success = 0
        self.embedding_total_fail = 0

        # ìë™ ì•Œë¦¼ í†µê³„
        self.notify_total_runs = 0
        self.notify_total_processed = 0
        self.notify_total_success = 0
        self.notify_total_failed = 0

        # ëª¨ë¸ í‰ê°€ í†µê³„
        self.evaluation_total_runs = 0
        self.evaluation_total_reports = 0
        self.evaluation_total_success = 0
        self.evaluation_total_failed = 0

        # KIS ì¼ë´‰ ìˆ˜ì§‘ í†µê³„
        self.kis_daily_total_runs = 0
        self.kis_daily_total_stocks = 0
        self.kis_daily_total_saved = 0
        self.kis_daily_total_errors = 0

        # KIS 1ë¶„ë´‰ ìˆ˜ì§‘ í†µê³„
        self.kis_minute_total_runs = 0
        self.kis_minute_total_stocks = 0
        self.kis_minute_total_saved = 0
        self.kis_minute_total_errors = 0

    def _crawl_all_sources(self) -> None:
        """
        ëª¨ë“  ì–¸ë¡ ì‚¬ì—ì„œ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info(f"ğŸ”„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘ (#{self.news_total_crawls + 1})")
        logger.info("=" * 60)

        db = SessionLocal()
        saver = NewsSaver(db)

        saved_total = 0
        skipped_total = 0

        try:
            # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§
            try:
                logger.info("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§...")
                with NaverNewsCrawler() as naver:
                    news_list = naver.fetch_news(limit=10)
                    if news_list:
                        saved, skipped = saver.save_news_batch(news_list)
                        saved_total += saved
                        skipped_total += skipped
                        logger.info(f"   âœ… ë„¤ì´ë²„: {saved}ê±´ ì €ì¥, {skipped}ê±´ ìŠ¤í‚µ")
                    else:
                        logger.warning("   âš ï¸  ë„¤ì´ë²„: ë‰´ìŠ¤ ì—†ìŒ")
            except Exception as e:
                self.news_total_errors += 1
                logger.error(f"   âŒ ë„¤ì´ë²„ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

            # 2. í•œêµ­ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§
            try:
                logger.info("ğŸ“° í•œêµ­ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§...")
                with HankyungNewsCrawler() as hankyung:
                    news_list = hankyung.fetch_news(limit=10)
                    if news_list:
                        saved, skipped = saver.save_news_batch(news_list)
                        saved_total += saved
                        skipped_total += skipped
                        logger.info(f"   âœ… í•œêµ­ê²½ì œ: {saved}ê±´ ì €ì¥, {skipped}ê±´ ìŠ¤í‚µ")
                    else:
                        logger.warning("   âš ï¸  í•œêµ­ê²½ì œ: ë‰´ìŠ¤ ì—†ìŒ")
            except Exception as e:
                self.news_total_errors += 1
                logger.error(f"   âŒ í•œêµ­ê²½ì œ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

            # 3. ë§¤ì¼ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§
            try:
                logger.info("ğŸ“° ë§¤ì¼ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§...")
                with MaeilNewsCrawler() as maeil:
                    news_list = maeil.fetch_news(limit=10)
                    if news_list:
                        saved, skipped = saver.save_news_batch(news_list)
                        saved_total += saved
                        skipped_total += skipped
                        logger.info(f"   âœ… ë§¤ì¼ê²½ì œ: {saved}ê±´ ì €ì¥, {skipped}ê±´ ìŠ¤í‚µ")
                    else:
                        logger.warning("   âš ï¸  ë§¤ì¼ê²½ì œ: ë‰´ìŠ¤ ì—†ìŒ")
            except Exception as e:
                self.news_total_errors += 1
                logger.error(f"   âŒ ë§¤ì¼ê²½ì œ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.news_total_crawls += 1
            self.news_total_saved += saved_total
            self.news_total_skipped += skipped_total

            # ì„±ê³µë¥  ê³„ì‚°
            success_rate = (
                (self.news_total_crawls - self.news_total_errors) / self.news_total_crawls * 100
                if self.news_total_crawls > 0
                else 0
            )

            logger.info("=" * 60)
            logger.info(f"âœ… ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ: {saved_total}ê±´ ì €ì¥, {skipped_total}ê±´ ìŠ¤í‚µ")
            logger.info(
                f"ğŸ“Š ë‰´ìŠ¤ ì „ì²´ í†µê³„: ì‹¤í–‰ {self.news_total_crawls}íšŒ, "
                f"ì €ì¥ {self.news_total_saved}ê±´, "
                f"ìŠ¤í‚µ {self.news_total_skipped}ê±´, "
                f"ì—ëŸ¬ {self.news_total_errors}íšŒ, "
                f"ì„±ê³µë¥  {success_rate:.1f}%"
            )
            logger.info("=" * 60)

        except Exception as e:
            self.news_total_errors += 1
            logger.error(f"âŒ ë‰´ìŠ¤ í¬ë¡¤ë§ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

        finally:
            db.close()

    def _crawl_stock_specific_news(self) -> None:
        """
        ì¢…ëª©ë³„ë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ìˆ˜ì§‘ëŸ‰ ì°¨ë“± ì ìš©.
        """
        logger.info("=" * 60)
        logger.info("ğŸ¯ ì¢…ëª©ë³„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œì‘")
        logger.info("=" * 60)

        db = SessionLocal()
        saver = NewsSaver(db)
        search_crawler = NaverNewsSearchCrawler()

        saved_total = 0
        skipped_total = 0

        try:
            # DBì—ì„œ í™œì„±í™”ëœ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
            stocks = db.query(Stock).filter(Stock.is_active == True).order_by(Stock.priority).all()

            logger.info(f"ğŸ“Š ê²€ìƒ‰ ëŒ€ìƒ ì¢…ëª©: {len(stocks)}ê°œ")

            for stock in stocks:
                try:
                    # ìš°ì„ ìˆœìœ„ë³„ ìˆ˜ì§‘ëŸ‰ ê²°ì •
                    if stock.priority <= 2:
                        limit = 10  # ë†’ì€ ìš°ì„ ìˆœìœ„
                    elif stock.priority == 3:
                        limit = 5   # ì¤‘ê°„ ìš°ì„ ìˆœìœ„
                    else:
                        limit = 3   # ë‚®ì€ ìš°ì„ ìˆœìœ„

                    logger.info(f"ğŸ” {stock.name} ({stock.code}) ê²€ìƒ‰ ì¤‘... (ìµœëŒ€ {limit}ê±´)")

                    # ì¢…ëª©ëª…ìœ¼ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰
                    # NAVERëŠ” í•œê¸€ë¡œ ê²€ìƒ‰ (ì˜ë¬¸ "NAVER"ë¡œ ê²€ìƒ‰í•˜ë©´ ì¶œì²˜ "ë„¤ì´ë²„"ê°€ ëª¨ë‘ ê²€ìƒ‰ë¨)
                    search_query = "ë„¤ì´ë²„" if stock.name == "NAVER" else stock.name

                    news_list = search_crawler.search_news(
                        query=search_query,
                        max_pages=1,
                        max_results=limit
                    )

                    if news_list:
                        # ë‰´ìŠ¤ì— ì¢…ëª©ì½”ë“œ ëª…ì‹œì  ì„¤ì •
                        for news in news_list:
                            news.company_name = stock.name
                            # stock_codeëŠ” news_saverì—ì„œ ìë™ ë§¤ì¹­ë˜ì§€ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥

                        saved, skipped = saver.save_news_batch(news_list)
                        saved_total += saved
                        skipped_total += skipped

                        if saved > 0:
                            logger.info(f"   âœ… {saved}ê±´ ì €ì¥, {skipped}ê±´ ìŠ¤í‚µ")
                        else:
                            logger.debug(f"   â­ï¸  ì „ë¶€ ì¤‘ë³µ ({skipped}ê±´)")
                    else:
                        logger.debug(f"   â„¹ï¸  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

                except Exception as e:
                    logger.error(f"   âŒ {stock.name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

            logger.info("=" * 60)
            logger.info(f"âœ… ì¢…ëª©ë³„ ê²€ìƒ‰ ì™„ë£Œ: {saved_total}ê±´ ì €ì¥, {skipped_total}ê±´ ìŠ¤í‚µ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ì¢…ëª©ë³„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

        finally:
            db.close()

    def _crawl_dart_disclosures(self) -> None:
        """
        DART ê³µì‹œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        Priority 1-2 ì¢…ëª©ë§Œ ëŒ€ìƒ (ì¤‘ìš” ì¢…ëª©ë§Œ)
        """
        logger.info("=" * 60)
        logger.info("ğŸ“‹ DART ê³µì‹œ ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        db = SessionLocal()
        saver = NewsSaver(db)
        dart_crawler = DartCrawler()

        # DART API í‚¤ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not dart_crawler.api_key:
            logger.warning("âš ï¸  DART API í‚¤ê°€ ì—†ì–´ ê³µì‹œ ìˆ˜ì§‘ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            logger.info("   API í‚¤ ë°œê¸‰: https://opendart.fss.or.kr/")
            db.close()
            return

        saved_total = 0
        skipped_total = 0

        try:
            # Priority 1-2 ì¢…ëª©ë§Œ ê³µì‹œ ìˆ˜ì§‘ (ì¤‘ìš” ì¢…ëª©)
            stocks = db.query(Stock).filter(
                Stock.is_active == True,
                Stock.priority <= 2
            ).all()

            logger.info(f"ğŸ“Š ê³µì‹œ ìˆ˜ì§‘ ëŒ€ìƒ: {len(stocks)}ê°œ (Priority 1-2ë§Œ)")

            for stock in stocks:
                try:
                    logger.info(f"ğŸ“‹ {stock.name} ({stock.code}) ê³µì‹œ ê²€ìƒ‰ ì¤‘...")

                    # ìµœê·¼ 3ì¼ê°„ ê³µì‹œ ê²€ìƒ‰
                    from datetime import datetime, timedelta
                    disclosures = dart_crawler.fetch_disclosures_by_stock_code(
                        stock_code=stock.code,
                        start_date=datetime.now() - timedelta(days=3),
                        end_date=datetime.now(),
                    )

                    if disclosures:
                        # ê³µì‹œì— ì¢…ëª© ì •ë³´ ì„¤ì •
                        for disclosure in disclosures:
                            disclosure.company_name = stock.name

                        saved, skipped = saver.save_news_batch(disclosures)
                        saved_total += saved
                        skipped_total += skipped

                        if saved > 0:
                            logger.info(f"   âœ… {saved}ê±´ ì €ì¥, {skipped}ê±´ ìŠ¤í‚µ")
                        else:
                            logger.debug(f"   â­ï¸  ì „ë¶€ ì¤‘ë³µ ({skipped}ê±´)")
                    else:
                        logger.debug(f"   â„¹ï¸  ê³µì‹œ ì—†ìŒ")

                except Exception as e:
                    logger.error(f"   âŒ {stock.name} ê³µì‹œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

            logger.info("=" * 60)
            logger.info(f"âœ… DART ê³µì‹œ ìˆ˜ì§‘ ì™„ë£Œ: {saved_total}ê±´ ì €ì¥, {skipped_total}ê±´ ìŠ¤í‚µ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ DART ê³µì‹œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

        finally:
            db.close()

    # FDR ì£¼ê°€ ìˆ˜ì§‘ ì œê±° - KIS APIë¡œ ì „í™˜ ì™„ë£Œ
    # _collect_stock_prices() ë©”ì„œë“œëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

    def _match_news_with_stocks(self) -> None:
        """
        ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        ë§¤ì¼ ì¥ ë§ˆê° í›„(15:40)ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info(f"ğŸ”— ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­ ì‹œì‘ (#{self.matching_total_runs + 1})")
        logger.info("=" * 60)

        db = SessionLocal()

        try:
            # ì¼ì¼ ë§¤ì¹­ ì‹¤í–‰ (ìµœê·¼ 7ì¼ ë‰´ìŠ¤ ëŒ€ìƒ)
            success_count, fail_count = run_daily_matching(db, lookback_days=7)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.matching_total_runs += 1
            self.matching_total_success += success_count
            self.matching_total_fail += fail_count

            # ì„±ê³µë¥  ê³„ì‚°
            total_attempts = self.matching_total_success + self.matching_total_fail
            success_rate = (
                (self.matching_total_success / total_attempts * 100) if total_attempts > 0 else 0
            )

            logger.info("=" * 60)
            logger.info(f"âœ… ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­ ì™„ë£Œ: ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {fail_count}ê±´")
            logger.info(
                f"ğŸ“Š ë§¤ì¹­ ì „ì²´ í†µê³„: ì‹¤í–‰ {self.matching_total_runs}íšŒ, "
                f"ì„±ê³µ {self.matching_total_success}ê±´, "
                f"ì‹¤íŒ¨ {self.matching_total_fail}ê±´, "
                f"ì„±ê³µë¥  {success_rate:.1f}%"
            )
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

        finally:
            db.close()

    def _embed_news(self) -> None:
        """
        ë‰´ìŠ¤ ì„ë² ë”© ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        ë§¤ì¼ ì¥ ë§ˆê° í›„(16:00)ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info(f"ğŸ”¤ ë‰´ìŠ¤ ì„ë² ë”© ì‹œì‘ (#{self.embedding_total_runs + 1})")
        logger.info("=" * 60)

        try:
            # ì¼ì¼ ì„ë² ë”© ì‹¤í–‰ (ë°°ì¹˜ 100ê±´)
            success_count, fail_count = run_daily_embedding(batch_size=100)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.embedding_total_runs += 1
            self.embedding_total_success += success_count
            self.embedding_total_fail += fail_count

            # ì„±ê³µë¥  ê³„ì‚°
            total_attempts = self.embedding_total_success + self.embedding_total_fail
            success_rate = (
                (self.embedding_total_success / total_attempts * 100)
                if total_attempts > 0
                else 0
            )

            logger.info("=" * 60)
            logger.info(f"âœ… ë‰´ìŠ¤ ì„ë² ë”© ì™„ë£Œ: ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {fail_count}ê±´")
            logger.info(
                f"ğŸ“Š ì„ë² ë”© ì „ì²´ í†µê³„: ì‹¤í–‰ {self.embedding_total_runs}íšŒ, "
                f"ì„±ê³µ {self.embedding_total_success}ê±´, "
                f"ì‹¤íŒ¨ {self.embedding_total_fail}ê±´, "
                f"ì„±ê³µë¥  {success_rate:.1f}%"
            )
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ì„ë² ë”© ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

    def _auto_notify(self) -> None:
        """
        ìµœê·¼ ë‰´ìŠ¤ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  í…”ë ˆê·¸ë¨ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
        ë‰´ìŠ¤ í¬ë¡¤ë§ ì§í›„ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info(f"ğŸ”” ìë™ ì•Œë¦¼ ì‹œì‘ (#{self.notify_total_runs + 1})")
        logger.info("=" * 60)

        db = SessionLocal()

        try:
            # ìµœê·¼ 15ë¶„ ì´ë‚´ ë‰´ìŠ¤ ì²˜ë¦¬
            stats = process_new_news_notifications(db, lookback_minutes=15)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.notify_total_runs += 1
            self.notify_total_processed += stats["processed"]
            self.notify_total_success += stats["success"]
            self.notify_total_failed += stats["failed"]

            # ì„±ê³µë¥  ê³„ì‚°
            total_attempts = self.notify_total_success + self.notify_total_failed
            success_rate = (
                (self.notify_total_success / total_attempts * 100)
                if total_attempts > 0
                else 0
            )

            logger.info("=" * 60)
            logger.info(
                f"âœ… ìë™ ì•Œë¦¼ ì™„ë£Œ: ì²˜ë¦¬ {stats['processed']}ê±´, "
                f"ì„±ê³µ {stats['success']}ê±´, ì‹¤íŒ¨ {stats['failed']}ê±´"
            )
            logger.info(
                f"ğŸ“Š ì•Œë¦¼ ì „ì²´ í†µê³„: ì‹¤í–‰ {self.notify_total_runs}íšŒ, "
                f"ì²˜ë¦¬ {self.notify_total_processed}ê±´, "
                f"ì„±ê³µ {self.notify_total_success}ê±´, "
                f"ì‹¤íŒ¨ {self.notify_total_failed}ê±´, "
                f"ì„±ê³µë¥  {success_rate:.1f}%"
            )
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ìë™ ì•Œë¦¼ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

        finally:
            db.close()

    async def _collect_kis_daily_prices(self) -> None:
        """
        KIS APIë¡œ ì¼ë´‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        ë§¤ì¼ ì¥ ë§ˆê° í›„(15:40)ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info(f"ğŸ“ˆ KIS ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (#{self.kis_daily_total_runs + 1})")
        logger.info("=" * 60)

        try:
            # KIS ì¼ë´‰ ìˆ˜ì§‘ê¸° ê°€ì ¸ì˜¤ê¸°
            crawler = get_kis_daily_crawler()

            # ê³¼ê±° 30ì¼ ë°ì´í„° ìˆ˜ì§‘
            summary = await crawler.collect_all_stocks(days=30, batch_size=10)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.kis_daily_total_runs += 1
            self.kis_daily_total_stocks += summary["total_stocks"]
            self.kis_daily_total_saved += summary["total_saved"]
            self.kis_daily_total_errors += summary["failed_count"]

            # ì„±ê³µë¥  ê³„ì‚°
            success_rate = summary["success_rate"]

            logger.info("=" * 60)
            logger.info(
                f"âœ… KIS ì¼ë´‰ ìˆ˜ì§‘ ì™„ë£Œ: {summary['success_count']}/{summary['total_stocks']}ê°œ ì¢…ëª©, "
                f"ì´ {summary['total_saved']}ê±´ ì €ì¥"
            )
            logger.info(
                f"ğŸ“Š KIS ì¼ë´‰ ì „ì²´ í†µê³„: ì‹¤í–‰ {self.kis_daily_total_runs}íšŒ, "
                f"ì²˜ë¦¬ {self.kis_daily_total_stocks}ê°œ ì¢…ëª©, "
                f"ì €ì¥ {self.kis_daily_total_saved}ê±´, "
                f"ì—ëŸ¬ {self.kis_daily_total_errors}íšŒ, "
                f"ì„±ê³µë¥  {success_rate:.1f}%"
            )
            logger.info("=" * 60)

        except Exception as e:
            self.kis_daily_total_errors += 1
            logger.error(f"âŒ KIS ì¼ë´‰ ìˆ˜ì§‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

    async def _collect_index_daily(self) -> None:
        """
        KIS APIë¡œ ì—…ì¢…/ì§€ìˆ˜ ì¼ìë³„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        ë§¤ì¼ ì¥ ë§ˆê° í›„(18:00)ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info("ğŸ“Š KIS ì—…ì¢…/ì§€ìˆ˜ ì¼ìë³„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        try:
            from backend.crawlers.index_daily_collector import IndexDailyCollector

            collector = IndexDailyCollector(batch_size=5)
            result = await collector.collect_today()

            logger.info("=" * 60)
            logger.info(
                f"âœ… ì—…ì¢…/ì§€ìˆ˜ ìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {result['collected']}ê±´, ì‹¤íŒ¨ {result['failed']}ê±´"
            )
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ì—…ì¢…/ì§€ìˆ˜ ìˆ˜ì§‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}", exc_info=True)

    async def _collect_kis_minute_prices(self) -> None:
        """
        KIS APIë¡œ 1ë¶„ë´‰ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        ì¥ ì‹œê°„(09:00~15:30)ì—ë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        # ì¥ ì‹œê°„ ì²´í¬
        if not is_market_open():
            logger.debug("â¸ï¸  1ë¶„ë´‰ ìˆ˜ì§‘ ìŠ¤í‚µ: ì¥ ë§ˆê°")
            return

        logger.info("=" * 60)
        logger.info(f"ğŸ“Š KIS 1ë¶„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (#{self.kis_minute_total_runs + 1})")
        logger.info("=" * 60)

        try:
            # 1ë¶„ë´‰ ìˆ˜ì§‘ê¸° ì‹¤í–‰
            await run_minute_collector()

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.kis_minute_total_runs += 1

            logger.info("=" * 60)
            logger.info("âœ… KIS 1ë¶„ë´‰ ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info(
                f"ğŸ“Š KIS 1ë¶„ë´‰ ì „ì²´ í†µê³„: ì‹¤í–‰ {self.kis_minute_total_runs}íšŒ"
            )
            logger.info("=" * 60)

        except Exception as e:
            self.kis_minute_total_errors += 1
            logger.error(f"âŒ KIS 1ë¶„ë´‰ ìˆ˜ì§‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

    async def _collect_market_data(self) -> None:
        """
        KIS APIë¡œ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ (í˜¸ê°€, í˜„ì¬ê°€, ì¢…ëª©ì •ë³´, ì—…ì¢…ì§€ìˆ˜).
        ì¥ ì‹œê°„(09:00~15:30)ì—ë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        # ì¥ ì‹œê°„ ì²´í¬
        if not is_market_open():
            logger.debug("â¸ï¸  ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í‚µ: ì¥ ë§ˆê°")
            return

        logger.info("=" * 60)
        logger.info("ğŸ“Š KIS ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        try:
            # í˜¸ê°€ ë°ì´í„° ìˆ˜ì§‘
            logger.info("ğŸ“ˆ í˜¸ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
            orderbook_collector = OrderbookCollector(batch_size=10)
            await orderbook_collector.collect_all()

            # í˜„ì¬ê°€ ë°ì´í„° ìˆ˜ì§‘
            logger.info("ğŸ’° í˜„ì¬ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
            current_price_collector = CurrentPriceCollector(batch_size=10)
            await current_price_collector.collect_all()

            # ì—…ì¢… ì§€ìˆ˜ ìˆ˜ì§‘
            logger.info("ğŸ“Š ì—…ì¢… ì§€ìˆ˜ ìˆ˜ì§‘ ì‹œì‘...")
            sector_index_collector = SectorIndexCollector()
            await sector_index_collector.collect_all()

            logger.info("=" * 60)
            logger.info("âœ… ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")

    async def _collect_investor_trading(self) -> None:
        """
        íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ë°ì´í„° ìˆ˜ì§‘.
        ë§¤ì¼ ì¥ ë§ˆê° í›„(16:00)ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info("ğŸ’¼ íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        try:
            # ìµœê·¼ 30ì¼ ë°ì´í„° ìˆ˜ì§‘
            collector = InvestorTradingCollector(batch_size=5)
            await collector.collect_all(days=30)

            logger.info("=" * 60)
            logger.info("âœ… íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")

    async def _collect_stock_info(self) -> None:
        """
        ì¢…ëª© ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘.
        ë§¤ì¼ ì¥ ë§ˆê° í›„(16:10)ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        logger.info("=" * 60)
        logger.info("â„¹ï¸  ì¢…ëª© ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        try:
            collector = StockInfoCollector(batch_size=10)
            await collector.collect_all()

            logger.info("=" * 60)
            logger.info("âœ… ì¢…ëª© ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ì¢…ëª© ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")

    async def _collect_overtime_prices(self) -> None:
        """
        ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²© ìˆ˜ì§‘.
        ë§¤ì¼ ì €ë… 18:00ì— ì‹¤í–‰ë©ë‹ˆë‹¤ (ì‹œê°„ì™¸ ê±°ë˜ ì¢…ë£Œ í›„).
        """
        logger.info("=" * 60)
        logger.info("ğŸŒ™ ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²© ìˆ˜ì§‘ ì‹œì‘")
        logger.info("=" * 60)

        try:
            from backend.crawlers.kis_market_data_collector import OvertimePriceCollector

            collector = OvertimePriceCollector(batch_size=10)
            await collector.collect_all()

            logger.info("=" * 60)
            logger.info("âœ… ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²© ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²© ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")

    async def _generate_stock_reports(self) -> None:
        """
        ì¢…ëª©ë³„ íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„±.
        í•˜ë£¨ 3ë²ˆ ì‹¤í–‰ë©ë‹ˆë‹¤ (09:15, 13:00, 15:40).
        Priority 1-2 ì¢…ëª©ë§Œ ëŒ€ìƒ.
        """
        logger.info("=" * 60)
        logger.info("ğŸ“ ì¢…ëª©ë³„ íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        logger.info("=" * 60)

        db = SessionLocal()

        try:
            from backend.services.stock_analysis_service import update_stock_analysis_summary

            # Priority 1-2 ì¢…ëª©ë§Œ ì¡°íšŒ
            priority_stocks = db.query(Stock).filter(
                Stock.is_active == True,
                Stock.priority <= 2
            ).all()

            logger.info(f"ğŸ“Š ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ìƒ: {len(priority_stocks)}ê°œ ì¢…ëª© (Priority 1-2)")

            success_count = 0
            failed_count = 0

            for stock in priority_stocks:
                try:
                    # ë¦¬í¬íŠ¸ ìƒì„± (force_update=Trueë¡œ í•­ìƒ ìƒˆë¡œ ìƒì„±)
                    report = await update_stock_analysis_summary(
                        stock_code=stock.code,
                        db=db,
                        force_update=True
                    )

                    if report:
                        success_count += 1
                        logger.info(
                            f"  âœ… {stock.name} ({stock.code}): "
                            f"ê¸°ì¤€ê°€ {report.base_price:,.0f}ì›, "
                            f"ëª©í‘œê°€ {report.short_term_target_price:,.0f}ì›"
                        )
                    else:
                        failed_count += 1
                        logger.warning(f"  âš ï¸  {stock.name} ({stock.code}) ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")

                except Exception as e:
                    failed_count += 1
                    logger.error(f"  âŒ {stock.name} ({stock.code}) ë¦¬í¬íŠ¸ ìƒì„± ì—ëŸ¬: {e}")

            logger.info("=" * 60)
            logger.info(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

        finally:
            db.close()

    def _generate_model_evaluations(self) -> None:
        """
        ìµœê·¼ íˆ¬ì ë¦¬í¬íŠ¸ì— ëŒ€í•œ ëª¨ë¸ í‰ê°€ ìƒì„±.
        ë§¤ì¼ 16:30ì— ì‹¤í–‰ë©ë‹ˆë‹¤ (ë¦¬í¬íŠ¸ ìƒì„± í›„).
        Priority 1-2 ì¢…ëª©ë§Œ ëŒ€ìƒ.
        """
        logger.info("=" * 60)
        logger.info(f"ğŸ¯ ëª¨ë¸ í‰ê°€ ìƒì„± ì‹œì‘ (#{self.evaluation_total_runs + 1})")
        logger.info("=" * 60)

        db = SessionLocal()

        try:
            from backend.services.evaluation_service import EvaluationService
            from backend.db.models.ab_test_config import ABTestConfig
            from backend.db.models.model import Model
            from datetime import datetime

            # ì˜¤ëŠ˜ ìƒì„±ëœ ë¦¬í¬íŠ¸ ì¡°íšŒ
            today = datetime.now()
            start_of_day = today.replace(hour=0, minute=0, second=0, microsecond=0)
            end_of_day = today.replace(hour=23, minute=59, second=59, microsecond=999999)

            reports = db.query(StockAnalysisSummary).filter(
                StockAnalysisSummary.last_updated >= start_of_day,
                StockAnalysisSummary.last_updated <= end_of_day,
                StockAnalysisSummary.base_price.isnot(None),
                StockAnalysisSummary.short_term_target_price.isnot(None),
                StockAnalysisSummary.short_term_support_price.isnot(None)
            ).all()

            # Priority 1-2 ì¢…ëª©ë§Œ í•„í„°ë§
            priority_stocks = db.query(Stock).filter(
                Stock.is_active == True,
                Stock.priority <= 2
            ).all()
            priority_codes = {s.code for s in priority_stocks}

            reports = [r for r in reports if r.stock_code in priority_codes]

            logger.info(f"ğŸ“Š í‰ê°€ ëŒ€ìƒ ë¦¬í¬íŠ¸: {len(reports)}ê±´ (Priority 1-2 ì¢…ëª©ë§Œ)")

            if not reports:
                logger.info("â­ï¸  í‰ê°€í•  ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                return

            # EvaluationService ì´ˆê¸°í™”
            service = EvaluationService(db)

            success_count = 0
            failed_count = 0

            # A/B í…ŒìŠ¤íŠ¸ ì„¤ì • ì¡°íšŒ
            ab_config = db.query(ABTestConfig).filter(ABTestConfig.is_active == True).first()

            for report in reports:
                try:
                    # A/B í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ì¸ ê²½ìš° ë‘ ëª¨ë¸ ëª¨ë‘ í‰ê°€
                    if report.custom_data and report.custom_data.get('ab_test_enabled') and ab_config:
                        model_a = db.query(Model).filter(Model.id == ab_config.model_a_id).first()
                        model_b = db.query(Model).filter(Model.id == ab_config.model_b_id).first()

                        # Model A í‰ê°€
                        try:
                            eval_a = service.evaluate_report(report, model_id=ab_config.model_a_id)
                            if eval_a:
                                success_count += 1
                                logger.info(
                                    f"  âœ… {report.stock_code} - Model A ({model_a.name}): "
                                    f"score={eval_a.final_score:.1f}"
                                )
                            else:
                                failed_count += 1
                                logger.warning(f"  âš ï¸  {report.stock_code} - Model A í‰ê°€ ì‹¤íŒ¨")
                        except Exception as e:
                            failed_count += 1
                            logger.error(f"  âŒ {report.stock_code} - Model A í‰ê°€ ì—ëŸ¬: {e}")

                        # Model B í‰ê°€
                        try:
                            eval_b = service.evaluate_report(report, model_id=ab_config.model_b_id)
                            if eval_b:
                                success_count += 1
                                logger.info(
                                    f"  âœ… {report.stock_code} - Model B ({model_b.name}): "
                                    f"score={eval_b.final_score:.1f}"
                                )
                            else:
                                failed_count += 1
                                logger.warning(f"  âš ï¸  {report.stock_code} - Model B í‰ê°€ ì‹¤íŒ¨")
                        except Exception as e:
                            failed_count += 1
                            logger.error(f"  âŒ {report.stock_code} - Model B í‰ê°€ ì—ëŸ¬: {e}")
                    else:
                        # ì¼ë°˜ ë¦¬í¬íŠ¸ (ë‹¨ì¼ ëª¨ë¸)
                        try:
                            evaluation = service.evaluate_report(report, model_id=1)
                            if evaluation:
                                success_count += 1
                                logger.info(
                                    f"  âœ… {report.stock_code}: score={evaluation.final_score:.1f}"
                                )
                            else:
                                failed_count += 1
                                logger.warning(f"  âš ï¸  {report.stock_code} í‰ê°€ ì‹¤íŒ¨")
                        except Exception as e:
                            failed_count += 1
                            logger.error(f"  âŒ {report.stock_code} í‰ê°€ ì—ëŸ¬: {e}")

                except Exception as e:
                    failed_count += 1
                    logger.error(f"  âŒ {report.stock_code} í‰ê°€ ì¤‘ ì—ëŸ¬: {e}")

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.evaluation_total_runs += 1
            self.evaluation_total_reports += len(reports)
            self.evaluation_total_success += success_count
            self.evaluation_total_failed += failed_count

            # ì„±ê³µë¥  ê³„ì‚°
            total_attempts = self.evaluation_total_success + self.evaluation_total_failed
            success_rate = (
                (self.evaluation_total_success / total_attempts * 100)
                if total_attempts > 0
                else 0
            )

            logger.info("=" * 60)
            logger.info(f"âœ… ëª¨ë¸ í‰ê°€ ìƒì„± ì™„ë£Œ: ì„±ê³µ {success_count}ê±´, ì‹¤íŒ¨ {failed_count}ê±´")
            logger.info(
                f"ğŸ“Š í‰ê°€ ì „ì²´ í†µê³„: ì‹¤í–‰ {self.evaluation_total_runs}íšŒ, "
                f"ë¦¬í¬íŠ¸ {self.evaluation_total_reports}ê±´, "
                f"ì„±ê³µ {self.evaluation_total_success}ê±´, "
                f"ì‹¤íŒ¨ {self.evaluation_total_failed}ê±´, "
                f"ì„±ê³µë¥  {success_rate:.1f}%"
            )
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ í‰ê°€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

        finally:
            db.close()

    def start(self) -> None:
        """ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        if self.is_running:
            logger.warning("ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return

        logger.info(
            f"ğŸš€ í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ "
            f"(ë‰´ìŠ¤: {self.news_interval_minutes}ë¶„, ì£¼ê°€: {self.stock_interval_minutes}ë¶„)"
        )

        self.scheduler = BackgroundScheduler()

        # ë‰´ìŠ¤ í¬ë¡¤ë§ ì‘ì—… ë“±ë¡ (10ë¶„ ê°„ê²©)
        news_trigger = IntervalTrigger(minutes=self.news_interval_minutes)
        self.scheduler.add_job(
            func=self._crawl_all_sources,
            trigger=news_trigger,
            id="news_crawler_job",
            name="ë‰´ìŠ¤ í¬ë¡¤ëŸ¬",
            replace_existing=True,
        )

        # ì¢…ëª©ë³„ ê²€ìƒ‰ ì‘ì—… ë“±ë¡ (10ë¶„ ê°„ê²©)
        stock_news_trigger = IntervalTrigger(minutes=self.news_interval_minutes)
        self.scheduler.add_job(
            func=self._crawl_stock_specific_news,
            trigger=stock_news_trigger,
            id="stock_news_search_job",
            name="ì¢…ëª©ë³„ ë‰´ìŠ¤ ê²€ìƒ‰",
            replace_existing=True,
        )

        # DART ê³µì‹œ í¬ë¡¤ë§ ì‘ì—… ë“±ë¡ (5ë¶„ ê°„ê²©)
        dart_trigger = IntervalTrigger(minutes=5)
        self.scheduler.add_job(
            func=self._crawl_dart_disclosures,
            trigger=dart_trigger,
            id="dart_disclosure_job",
            name="DART ê³µì‹œ í¬ë¡¤ë§",
            replace_existing=True,
        )

        # FDR ì£¼ê°€ ìˆ˜ì§‘ ì œê±° - KIS APIë¡œ ì „í™˜ ì™„ë£Œ

        # ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­ ì‘ì—… ë“±ë¡ (ë§¤ì¼ 15:40)
        matching_trigger = CronTrigger(hour=15, minute=40)
        self.scheduler.add_job(
            func=self._match_news_with_stocks,
            trigger=matching_trigger,
            id="news_stock_matching_job",
            name="ë‰´ìŠ¤-ì£¼ê°€ ë§¤ì¹­",
            replace_existing=True,
        )

        # ë‰´ìŠ¤ ì„ë² ë”© ì‘ì—… ë“±ë¡ (ë§¤ì¼ 16:00)
        embedding_trigger = CronTrigger(hour=16, minute=0)
        self.scheduler.add_job(
            func=self._embed_news,
            trigger=embedding_trigger,
            id="news_embedding_job",
            name="ë‰´ìŠ¤ ì„ë² ë”©",
            replace_existing=True,
        )

        # ìë™ ì•Œë¦¼ ì‘ì—… ë“±ë¡ (ë‰´ìŠ¤ í¬ë¡¤ë§ê³¼ ë™ì¼í•œ ì£¼ê¸°)
        notify_trigger = IntervalTrigger(minutes=self.news_interval_minutes)
        self.scheduler.add_job(
            func=self._auto_notify,
            trigger=notify_trigger,
            id="auto_notify_job",
            name="ìë™ ì•Œë¦¼",
            replace_existing=True,
        )

        # KIS ì—…ì¢…/ì§€ìˆ˜ ì¼ìë³„ ìˆ˜ì§‘ ì‘ì—… ë“±ë¡ (ë§¤ì¼ 18:00 - ì‹œê°„ì™¸ ê±°ë˜ ë§ˆê° í›„)
        index_daily_trigger = CronTrigger(hour=18, minute=0)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_index_daily()),
            trigger=index_daily_trigger,
            id="kis_index_daily_job",
            name="KIS ì—…ì¢…/ì§€ìˆ˜ ì¼ìë³„ ìˆ˜ì§‘ê¸°",
            replace_existing=True,
        )

        # KIS ì¼ë´‰ ìˆ˜ì§‘ ì‘ì—… ë“±ë¡ (ë§¤ì¼ 15:40 - ì¥ ë§ˆê° í›„)
        kis_daily_trigger = CronTrigger(hour=15, minute=40)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_kis_daily_prices()),
            trigger=kis_daily_trigger,
            id="kis_daily_collector_job",
            name="KIS ì¼ë´‰ ìˆ˜ì§‘ê¸°",
            replace_existing=True,
        )

        # KIS 1ë¶„ë´‰ ìˆ˜ì§‘ ì‘ì—… ë“±ë¡ (ë§¤ 1ë¶„ - ì¥ ì‹œê°„ë§Œ)
        kis_minute_trigger = IntervalTrigger(minutes=1)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_kis_minute_prices()),
            trigger=kis_minute_trigger,
            id="kis_minute_collector_job",
            name="KIS 1ë¶„ë´‰ ìˆ˜ì§‘ê¸°",
            replace_existing=True,
        )

        # KIS ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… ë“±ë¡ (ë§¤ 5ë¶„ - ì¥ ì‹œê°„ë§Œ)
        market_data_trigger = IntervalTrigger(minutes=5)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_market_data()),
            trigger=market_data_trigger,
            id="kis_market_data_job",
            name="KIS ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘",
            replace_existing=True,
        )

        # íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘ (ë§¤ì¼ 16:00 - ì¥ ë§ˆê° í›„)
        investor_trading_trigger = CronTrigger(hour=16, minute=0)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_investor_trading()),
            trigger=investor_trading_trigger,
            id="investor_trading_job",
            name="íˆ¬ììë³„ ë§¤ë§¤ë™í–¥ ìˆ˜ì§‘",
            replace_existing=True,
        )

        # ì¢…ëª© ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘ (ë§¤ì¼ 16:10 - ì¥ ë§ˆê° í›„)
        stock_info_trigger = CronTrigger(hour=16, minute=10)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_stock_info()),
            trigger=stock_info_trigger,
            id="stock_info_job",
            name="ì¢…ëª© ê¸°ë³¸ì •ë³´ ìˆ˜ì§‘",
            replace_existing=True,
        )

        # ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²© ìˆ˜ì§‘ (ë§¤ì¼ 18:00 - ì‹œê°„ì™¸ ê±°ë˜ ì¢…ë£Œ í›„)
        overtime_trigger = CronTrigger(hour=18, minute=0)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._collect_overtime_prices()),
            trigger=overtime_trigger,
            id="overtime_price_job",
            name="ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²© ìˆ˜ì§‘",
            replace_existing=True,
        )

        # ë¦¬í¬íŠ¸ ìƒì„± (í•˜ë£¨ 3ë²ˆ - ì¥ ì‹œì‘ í›„, ì ì‹¬ í›„, ì¥ ë§ˆê° í›„)
        # ì¥ ì‹œì‘ í›„ (09:15)
        report_morning_trigger = CronTrigger(hour=9, minute=15)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._generate_stock_reports()),
            trigger=report_morning_trigger,
            id="stock_report_morning_job",
            name="íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± (ì¥ì´ˆ)",
            replace_existing=True,
        )

        # ì ì‹¬ ì‹œê°„ í›„ (13:00)
        report_lunch_trigger = CronTrigger(hour=13, minute=0)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._generate_stock_reports()),
            trigger=report_lunch_trigger,
            id="stock_report_lunch_job",
            name="íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± (ì¥ì¤‘)",
            replace_existing=True,
        )

        # ì¥ ë§ˆê° í›„ (15:40)
        report_close_trigger = CronTrigger(hour=15, minute=40)
        self.scheduler.add_job(
            func=lambda: asyncio.run(self._generate_stock_reports()),
            trigger=report_close_trigger,
            id="stock_report_close_job",
            name="íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± (ì¥ë§ˆê°)",
            replace_existing=True,
        )

        # ëª¨ë¸ í‰ê°€ ìƒì„± (ë§¤ì¼ 16:30 - ë¦¬í¬íŠ¸ ìƒì„± í›„)
        evaluation_trigger = CronTrigger(hour=16, minute=30)
        self.scheduler.add_job(
            func=self._generate_model_evaluations,
            trigger=evaluation_trigger,
            id="model_evaluation_job",
            name="ëª¨ë¸ í‰ê°€ ìƒì„±",
            replace_existing=True,
        )

        self.scheduler.start()
        self.is_running = True

        logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ")
        logger.info("â° í¬ë¡¤ëŸ¬ë“¤ì´ ìŠ¤ì¼€ì¤„ì— ë”°ë¼ ìë™ ì‹¤í–‰ë©ë‹ˆë‹¤")
        logger.info("   - ìµœì‹  ë‰´ìŠ¤: 10ë¶„ë§ˆë‹¤")
        logger.info("   - ì¢…ëª©ë³„ ê²€ìƒ‰: 10ë¶„ë§ˆë‹¤")
        logger.info("   - DART ê³µì‹œ: 5ë¶„ë§ˆë‹¤")
        logger.info("   - íˆ¬ì ë¦¬í¬íŠ¸: ë§¤ì¼ 09:15 (ì¥ì´ˆ), 13:00 (ì¥ì¤‘), 15:40 (ì¥ë§ˆê°)")
        logger.info("   - KIS ì¼ë´‰ ìˆ˜ì§‘: ë§¤ì¼ 15:40 (ì¥ ë§ˆê° í›„)")
        logger.info("   - KIS 1ë¶„ë´‰ ìˆ˜ì§‘: ë§¤ 1ë¶„ (ì¥ ì‹œê°„ë§Œ)")
        logger.info("   - KIS ì‹œì¥ ë°ì´í„°: ë§¤ 5ë¶„ (í˜¸ê°€, í˜„ì¬ê°€, ì—…ì¢…ì§€ìˆ˜ - ì¥ ì‹œê°„ë§Œ)")
        logger.info("   - íˆ¬ììë³„ ë§¤ë§¤ë™í–¥: ë§¤ì¼ 16:00 (ì¥ ë§ˆê° í›„)")
        logger.info("   - ì¢…ëª© ê¸°ë³¸ì •ë³´: ë§¤ì¼ 16:10 (ì¥ ë§ˆê° í›„)")
        logger.info("   - ëª¨ë¸ í‰ê°€ ìƒì„±: ë§¤ì¼ 16:30 (ë¦¬í¬íŠ¸ ìƒì„± í›„)")
        logger.info("   - ì‹œê°„ì™¸ ê±°ë˜ ê°€ê²©: ë§¤ì¼ 18:00 (ì‹œê°„ì™¸ ê±°ë˜ ì¢…ë£Œ í›„)")
        logger.info("   - KIS ì—…ì¢…/ì§€ìˆ˜ ì¼ìë³„: ë§¤ì¼ 18:00 (ì‹œê°„ì™¸ ê±°ë˜ ì¢…ë£Œ í›„)")

        # ì´ˆê¸° ì‹¤í–‰ì€ ì„ íƒì‚¬í•­ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
        # ì²« ìŠ¤ì¼€ì¤„ê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ” ê²ƒì´ ì„œë²„ ì‹œì‘ì„ ë¹ ë¥´ê²Œ í•©ë‹ˆë‹¤
        import os
        if os.getenv("RUN_INITIAL_CRAWL", "false").lower() == "true":
            logger.info("ğŸ”„ ì´ˆê¸° í¬ë¡¤ë§ ì‹¤í–‰...")
            self._crawl_all_sources()
            self._crawl_stock_specific_news()
            self._crawl_dart_disclosures()
        else:
            logger.info("â­ï¸  ì´ˆê¸° í¬ë¡¤ë§ ìŠ¤í‚µ - ì²« ìŠ¤ì¼€ì¤„ê¹Œì§€ ëŒ€ê¸° ì¤‘...")

    def shutdown(self) -> None:
        """ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        if not self.is_running:
            logger.warning("ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return

        logger.info("ğŸ›‘ í¬ë¡¤ëŸ¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì¤‘...")

        if self.scheduler:
            self.scheduler.shutdown(wait=False)

        self.is_running = False
        logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ ì™„ë£Œ")

    def get_stats(self) -> dict:
        """
        í¬ë¡¤ë§ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            í†µê³„ ë”•ì…”ë„ˆë¦¬ (ë‰´ìŠ¤, ì£¼ê°€, ë§¤ì¹­, ì„ë² ë”© í†µê³„)
        """
        # ë‰´ìŠ¤ ì„±ê³µë¥ 
        news_success_rate = (
            (self.news_total_crawls - self.news_total_errors) / self.news_total_crawls * 100
            if self.news_total_crawls > 0
            else 0
        )

        # ì£¼ê°€ ì„±ê³µë¥ 
        stock_success_rate = (
            (self.stock_total_crawls - self.stock_total_errors) / self.stock_total_crawls * 100
            if self.stock_total_crawls > 0
            else 0
        )

        # ë§¤ì¹­ ì„±ê³µë¥ 
        total_matching_attempts = self.matching_total_success + self.matching_total_fail
        matching_success_rate = (
            (self.matching_total_success / total_matching_attempts * 100)
            if total_matching_attempts > 0
            else 0
        )

        # ì„ë² ë”© ì„±ê³µë¥ 
        total_embedding_attempts = self.embedding_total_success + self.embedding_total_fail
        embedding_success_rate = (
            (self.embedding_total_success / total_embedding_attempts * 100)
            if total_embedding_attempts > 0
            else 0
        )

        # KIS ì¼ë´‰ ì„±ê³µë¥ 
        kis_daily_success_rate = (
            (self.kis_daily_total_runs - self.kis_daily_total_errors) / self.kis_daily_total_runs * 100
            if self.kis_daily_total_runs > 0
            else 0
        )

        # KIS 1ë¶„ë´‰ ì„±ê³µë¥ 
        kis_minute_success_rate = (
            (self.kis_minute_total_runs - self.kis_minute_total_errors) / self.kis_minute_total_runs * 100
            if self.kis_minute_total_runs > 0
            else 0
        )

        # ëª¨ë¸ í‰ê°€ ì„±ê³µë¥ 
        evaluation_success_rate = (
            (self.evaluation_total_success / (self.evaluation_total_success + self.evaluation_total_failed) * 100)
            if (self.evaluation_total_success + self.evaluation_total_failed) > 0
            else 0
        )

        return {
            "news": {
                "total_crawls": self.news_total_crawls,
                "total_saved": self.news_total_saved,
                "total_skipped": self.news_total_skipped,
                "total_errors": self.news_total_errors,
                "success_rate": round(news_success_rate, 2),
            },
            "stock": {
                "total_crawls": self.stock_total_crawls,
                "total_stocks": self.stock_total_stocks,
                "total_saved": self.stock_total_saved,
                "total_errors": self.stock_total_errors,
                "success_rate": round(stock_success_rate, 2),
            },
            "matching": {
                "total_runs": self.matching_total_runs,
                "total_success": self.matching_total_success,
                "total_fail": self.matching_total_fail,
                "success_rate": round(matching_success_rate, 2),
            },
            "embedding": {
                "total_runs": self.embedding_total_runs,
                "total_success": self.embedding_total_success,
                "total_fail": self.embedding_total_fail,
                "success_rate": round(embedding_success_rate, 2),
            },
            "evaluation": {
                "total_runs": self.evaluation_total_runs,
                "total_reports": self.evaluation_total_reports,
                "total_success": self.evaluation_total_success,
                "total_failed": self.evaluation_total_failed,
                "success_rate": round(evaluation_success_rate, 2),
            },
            "kis_daily": {
                "total_runs": self.kis_daily_total_runs,
                "total_stocks": self.kis_daily_total_stocks,
                "total_saved": self.kis_daily_total_saved,
                "total_errors": self.kis_daily_total_errors,
                "success_rate": round(kis_daily_success_rate, 2),
            },
            "kis_minute": {
                "total_runs": self.kis_minute_total_runs,
                "total_stocks": self.kis_minute_total_stocks,
                "total_saved": self.kis_minute_total_saved,
                "total_errors": self.kis_minute_total_errors,
                "success_rate": round(kis_minute_success_rate, 2),
            },
            "is_running": self.is_running,
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_crawler_scheduler: Optional[CrawlerScheduler] = None


def get_crawler_scheduler(
    news_interval_minutes: int = 10, stock_interval_minutes: int = 1
) -> CrawlerScheduler:
    """
    CrawlerScheduler ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        news_interval_minutes: ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰ ê°„ê²© (ë¶„)
        stock_interval_minutes: ì£¼ê°€ ìˆ˜ì§‘ ì‹¤í–‰ ê°„ê²© (ë¶„)

    Returns:
        CrawlerScheduler ì¸ìŠ¤í„´ìŠ¤
    """
    global _crawler_scheduler
    if _crawler_scheduler is None:
        _crawler_scheduler = CrawlerScheduler(news_interval_minutes, stock_interval_minutes)
    return _crawler_scheduler
