"""
ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë“ˆ

ìœ ì‚¬ ë‰´ìŠ¤ ê¸°ë°˜ LLM ì£¼ê°€ ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""
import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

from openai import OpenAI
from sqlalchemy.orm import Session

from backend.config import settings
from backend.llm.prediction_cache import get_prediction_cache
from backend.db.models.stock import StockPrice, Stock
from backend.db.models.news import NewsArticle
from backend.db.session import SessionLocal


logger = logging.getLogger(__name__)


class StockPredictor:
    """LLM ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™”"""
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o"  # GPT-4 Omni ëª¨ë¸ ì‚¬ìš©
        self.cache = get_prediction_cache()

    def _get_stock_info(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        ì¢…ëª© ê¸°ë³¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ

        Returns:
            ì¢…ëª© ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        db = SessionLocal()
        try:
            stock = db.query(Stock).filter(Stock.code == stock_code).first()
            if not stock:
                return None

            return {
                "code": stock.code,
                "name": stock.name,
                "priority": stock.priority,
            }
        except Exception as e:
            logger.error(f"ì¢…ëª© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (ì¢…ëª©ì½”ë“œ: {stock_code}): {e}")
            return None
        finally:
            db.close()

    def _get_current_stock_info(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        í˜„ì¬ ì£¼ê°€ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ

        Returns:
            ì£¼ê°€ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
            {
                "close": ì¢…ê°€,
                "open": ì‹œê°€,
                "high": ê³ ê°€,
                "low": ì €ê°€,
                "volume": ê±°ë˜ëŸ‰,
                "change_rate": ì „ì¼ ëŒ€ë¹„ ë³€ë™ë¥  (%),
                "date": ë‚ ì§œ
            }
        """
        db = SessionLocal()
        try:
            # ìµœê·¼ 2ì¼ ë°ì´í„° ì¡°íšŒ (ë³€ë™ë¥  ê³„ì‚°ìš©)
            recent_prices = (
                db.query(StockPrice)
                .filter(StockPrice.stock_code == stock_code)
                .order_by(StockPrice.date.desc())
                .limit(2)
                .all()
            )

            if not recent_prices:
                return None

            current = recent_prices[0]

            # ë³€ë™ë¥  ê³„ì‚°
            change_rate = 0.0
            if len(recent_prices) >= 2:
                previous = recent_prices[1]
                if previous.close > 0:
                    change_rate = ((current.close - previous.close) / previous.close) * 100

            return {
                "close": current.close,
                "open": current.open,
                "high": current.high,
                "low": current.low,
                "volume": current.volume,
                "change_rate": round(change_rate, 2),
                "date": current.date.strftime("%Y-%m-%d %H:%M") if current.date else "N/A",
            }

        except Exception as e:
            logger.error(f"í˜„ì¬ ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨ (ì¢…ëª©ì½”ë“œ: {stock_code}): {e}")
            return None
        finally:
            db.close()

    def _get_recent_disclosures(self, stock_code: str, days: int = 7) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ DART ê³µì‹œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            days: ì¡°íšŒí•  ê¸°ê°„ (ì¼)

        Returns:
            ê³µì‹œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        db = SessionLocal()
        try:
            since_date = datetime.now() - timedelta(days=days)

            disclosures = (
                db.query(NewsArticle)
                .filter(
                    NewsArticle.stock_code == stock_code,
                    NewsArticle.source == "dart",
                    NewsArticle.published_at >= since_date
                )
                .order_by(NewsArticle.published_at.desc())
                .limit(5)
                .all()
            )

            return [
                {
                    "title": disc.title,
                    "published_at": disc.published_at.strftime("%Y-%m-%d"),
                    "content": disc.content[:100] + "..." if len(disc.content) > 100 else disc.content,
                }
                for disc in disclosures
            ]

        except Exception as e:
            logger.error(f"DART ê³µì‹œ ì¡°íšŒ ì‹¤íŒ¨ (ì¢…ëª©ì½”ë“œ: {stock_code}): {e}")
            return []
        finally:
            db.close()

    def _get_market_context(self) -> Dict[str, Any]:
        """
        ì‹œì¥ ì§€ìˆ˜ ë§¥ë½ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Returns:
            ì‹œì¥ ì§€ìˆ˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        db = SessionLocal()
        try:
            from sqlalchemy import text

            # KOSPI ìµœì‹  ë°ì´í„°
            kospi_result = db.execute(
                text("""
                    SELECT close, change_pct, date
                    FROM market_indices
                    WHERE index_name = 'KOSPI'
                    ORDER BY date DESC
                    LIMIT 1
                """)
            )
            kospi_row = kospi_result.fetchone()

            # KOSDAQ ìµœì‹  ë°ì´í„°
            kosdaq_result = db.execute(
                text("""
                    SELECT close, change_pct, date
                    FROM market_indices
                    WHERE index_name = 'KOSDAQ'
                    ORDER BY date DESC
                    LIMIT 1
                """)
            )
            kosdaq_row = kosdaq_result.fetchone()

            return {
                "kospi": {
                    "close": round(kospi_row[0], 2) if kospi_row else None,
                    "change_pct": round(kospi_row[1], 2) if kospi_row else None,
                    "date": kospi_row[2].strftime("%Y-%m-%d") if kospi_row else None,
                } if kospi_row else None,
                "kosdaq": {
                    "close": round(kosdaq_row[0], 2) if kosdaq_row else None,
                    "change_pct": round(kosdaq_row[1], 2) if kosdaq_row else None,
                    "date": kosdaq_row[2].strftime("%Y-%m-%d") if kosdaq_row else None,
                } if kosdaq_row else None,
            }

        except Exception as e:
            logger.error(f"ì‹œì¥ ì§€ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"kospi": None, "kosdaq": None}
        finally:
            db.close()

    def _calculate_similar_news_stats(self, similar_news: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ìœ ì‚¬ ë‰´ìŠ¤ íŒ¨í„´ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        Args:
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not similar_news:
            return {
                "count": 0,
                "avg_similarity": 0.0,
                "pattern_stats": {"1d": {}, "2d": {}, "3d": {}, "5d": {}, "10d": {}, "20d": {}},
            }

        # ìœ ì‚¬ë„ í‰ê·  ê³„ì‚°
        similarities = [news.get("similarity", 0) for news in similar_news]
        avg_similarity = sum(similarities) / len(similarities) if similarities else 0.0

        # ê° ê¸°ê°„ë³„ ë³€ë™ë¥  í†µê³„ (T+1, T+2, T+3, T+5, T+10, T+20)
        pattern_stats = {}
        for period in ["1d", "2d", "3d", "5d", "10d", "20d"]:
            changes = []
            for news in similar_news:
                price_info = news.get("price_changes", {})
                change = price_info.get(period)
                if change is not None and change != "N/A":
                    try:
                        changes.append(float(change))
                    except (ValueError, TypeError):
                        pass

            if changes:
                pattern_stats[period] = {
                    "avg": round(sum(changes) / len(changes), 2),
                    "max": round(max(changes), 2),
                    "min": round(min(changes), 2),
                    "count": len(changes),
                }
            else:
                pattern_stats[period] = {"avg": None, "max": None, "min": None, "count": 0}

        return {
            "count": len(similar_news),
            "avg_similarity": round(avg_similarity, 4),
            "pattern_stats": pattern_stats,
        }

    def _build_prompt(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
    ) -> str:
        """
        ì˜ˆì¸¡ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê°œì„  ë²„ì „)

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´ {title, content, stock_code}
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [{title, content, similarity, price_changes}]

        Returns:
            í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        stock_code = current_news.get('stock_code')

        # 1. ì¢…ëª© ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
        stock_basic = self._get_stock_info(stock_code) if stock_code else None
        stock_name = stock_basic['name'] if stock_basic else "ì•Œ ìˆ˜ ì—†ìŒ"

        # 2. ìœ ì‚¬ ë‰´ìŠ¤ í†µê³„ ê³„ì‚°
        similar_stats = self._calculate_similar_news_stats(similar_news)

        # 3. ìœ ì‚¬ ë‰´ìŠ¤ ìš”ì•½
        similar_cases = []
        for i, news in enumerate(similar_news, 1):
            price_info = news.get("price_changes", {})
            similar_cases.append(
                f"""
### ìœ ì‚¬ ì‚¬ë¡€ {i} (ìœ ì‚¬ë„: {news.get('similarity', 0):.2%})
**ì œëª©**: {news.get('news_title', 'N/A')}
**ë‚´ìš©**: {news.get('news_content', 'N/A')[:150]}...
**ë°œí‘œì¼**: {news.get('published_at', 'N/A')}
**ì£¼ê°€ ë³€ë™ë¥ **:
- T+1ì¼: {price_info.get('1d', 'N/A')}%, T+2ì¼: {price_info.get('2d', 'N/A')}%
- T+3ì¼: {price_info.get('3d', 'N/A')}%, T+5ì¼: {price_info.get('5d', 'N/A')}%
- T+10ì¼: {price_info.get('10d', 'N/A')}%, T+20ì¼: {price_info.get('20d', 'N/A')}%
"""
            )

        similar_section = "\n".join(similar_cases) if similar_cases else "ìœ ì‚¬ ë‰´ìŠ¤ ì—†ìŒ"

        # 4. ìœ ì‚¬ íŒ¨í„´ í†µê³„ ì„¹ì…˜
        pattern_stats = similar_stats['pattern_stats']
        stats_section = f"""
## ğŸ“Š ìœ ì‚¬ ë‰´ìŠ¤ íŒ¨í„´ í†µê³„ (ì´ {similar_stats['count']}ê±´, í‰ê·  ìœ ì‚¬ë„: {similar_stats['avg_similarity']:.1%})

"""
        for period, stats in pattern_stats.items():
            if stats.get('count', 0) > 0:
                stats_section += f"""**T+{period.replace('d', '')}ì¼**: í‰ê·  {stats['avg']:+.2f}%, ìµœëŒ€ {stats['max']:+.2f}%, ìµœì†Œ {stats['min']:+.2f}% (ë°ì´í„° {stats['count']}ê±´)
"""
            else:
                stats_section += f"""**T+{period.replace('d', '')}ì¼**: ë°ì´í„° ì—†ìŒ
"""

        # 5. í˜„ì¬ ì£¼ê°€ ì •ë³´ ì¡°íšŒ
        stock_price = self._get_current_stock_info(stock_code) if stock_code else None

        # 6. í˜„ì¬ ì£¼ê°€ ì •ë³´ ì„¹ì…˜
        if stock_price:
            change_indicator = "ğŸ“ˆ" if stock_price["change_rate"] > 0 else "ğŸ“‰" if stock_price["change_rate"] < 0 else "â¡ï¸"
            price_section = f"""
## í˜„ì¬ ì£¼ê°€ ì •ë³´ ({stock_price['date']})
**í˜„ì¬ê°€**: {stock_price['close']:,.0f}ì› ({change_indicator} {stock_price['change_rate']:+.2f}%)
**ë‹¹ì¼ ë³€ë™**: ì‹œê°€ {stock_price['open']:,.0f}ì› / ê³ ê°€ {stock_price['high']:,.0f}ì› / ì €ê°€ {stock_price['low']:,.0f}ì›
**ê±°ë˜ëŸ‰**: {stock_price['volume']:,}ì£¼

**âš ï¸ ì¤‘ìš”**: ì´ ì£¼ê°€ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
- ìµœê·¼ ì£¼ê°€ íë¦„ì´ ìƒìŠ¹ì„¸ë¼ë©´ ê¸ì •ì  ë‰´ìŠ¤ì˜ ì˜í–¥ì´ ë” í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ìµœê·¼ ì£¼ê°€ê°€ í•˜ë½ì„¸ë¼ë©´ ë¶€ì •ì  ë‰´ìŠ¤ì˜ ì˜í–¥ì„ ë” ì‹ ì¤‘íˆ í‰ê°€í•˜ì„¸ìš”
"""
        else:
            price_section = "\n## í˜„ì¬ ì£¼ê°€ ì •ë³´\ní˜„ì¬ ì£¼ê°€ ì •ë³´ ì—†ìŒ\n"

        # 7. ìµœê·¼ DART ê³µì‹œ ì •ë³´ ì¡°íšŒ
        disclosures = self._get_recent_disclosures(stock_code, days=7) if stock_code else []

        if disclosures:
            disclosure_section = f"""
## ğŸ“¢ ìµœê·¼ 7ì¼ ê³µì‹œ ì •ë³´ ({len(disclosures)}ê±´)
"""
            for i, disc in enumerate(disclosures, 1):
                disclosure_section += f"""**{i}. [{disc['published_at']}] {disc['title']}**
ë‚´ìš©: {disc['content']}

"""
        else:
            disclosure_section = "\n## ğŸ“¢ ìµœê·¼ ê³µì‹œ ì •ë³´\nìµœê·¼ 7ì¼ ë‚´ ê³µì‹œ ì—†ìŒ\n"

        # 8. ì‹œì¥ ì§€ìˆ˜ ë§¥ë½ ì •ë³´ ì¡°íšŒ
        market_context = self._get_market_context()

        market_section = "\n## ğŸ“ˆ ì‹œì¥ ì§€ìˆ˜ í˜„í™©\n"
        if market_context.get("kospi"):
            kospi = market_context["kospi"]
            indicator = "ğŸ“ˆ" if kospi["change_pct"] > 0 else "ğŸ“‰" if kospi["change_pct"] < 0 else "â¡ï¸"
            market_section += f"""**KOSPI**: {kospi['close']:,.2f} ({indicator} {kospi['change_pct']:+.2f}%) - {kospi['date']}
"""
        if market_context.get("kosdaq"):
            kosdaq = market_context["kosdaq"]
            indicator = "ğŸ“ˆ" if kosdaq["change_pct"] > 0 else "ğŸ“‰" if kosdaq["change_pct"] < 0 else "â¡ï¸"
            market_section += f"""**KOSDAQ**: {kosdaq['close']:,.2f} ({indicator} {kosdaq['change_pct']:+.2f}%) - {kosdaq['date']}
"""
        if not market_context.get("kospi") and not market_context.get("kosdaq"):
            market_section += "ì‹œì¥ ì§€ìˆ˜ ì •ë³´ ì—†ìŒ\n"

        market_section += """
**âš ï¸ ì‹œì¥ ë§¥ë½ ê³ ë ¤ì‚¬í•­**:
- ì‹œì¥ ì „ì²´ê°€ ìƒìŠ¹ì„¸ë¼ë©´ ê°œë³„ ì¢…ëª©ì˜ ê¸ì •ì  ë‰´ìŠ¤ ì˜í–¥ì´ ì¦í­ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì‹œì¥ì´ í•˜ë½ì„¸ë¼ë©´ ë¶€ì •ì  ë‰´ìŠ¤ì˜ ì˜í–¥ì´ ë” í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
"""

        # 9. ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ **ì¢…í•© íˆ¬ì ì–´ë“œë°”ì´ì €**ì…ë‹ˆë‹¤.
ë‰´ìŠ¤, ê³µì‹œ, ê³¼ê±° íŒ¨í„´, í˜„ì¬ ì£¼ê°€ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ì„ ì œê³µí•˜ì„¸ìš”.

---

## í˜„ì¬ ë‰´ìŠ¤
**ì¢…ëª©**: {stock_name} ({stock_code})
**ì œëª©**: {current_news.get('title', 'N/A')}
**ë‚´ìš©**: {current_news.get('content', 'N/A')[:300]}...

---
{price_section}
---
{market_section}
---
{disclosure_section}
---
{stats_section}
---

## ìœ ì‚¬í•œ ê³¼ê±° ë‰´ìŠ¤ì™€ ì‹¤ì œ ì£¼ê°€ ë³€ë™
{similar_section}

---

## ë¶„ì„ ìš”ì²­ì‚¬í•­

1. **íŒ¨í„´ ë¶„ì„**: ìœ„ í†µê³„ë¥¼ ì°¸ê³ í•˜ì—¬ ìœ ì‚¬ ë‰´ìŠ¤ë“¤ì˜ ì£¼ê°€ ë³€ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ì„¸ìš”
2. **ì˜ˆì¸¡**: í˜„ì¬ ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ì„ ì˜ˆì¸¡í•˜ì„¸ìš” (ìƒìŠ¹/í•˜ë½/ìœ ì§€)
3. **ì‹ ë¢°ë„ ê³„ì‚°**: ë‹¤ìŒ ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•˜ê³ , ê° ìš”ì†Œì˜ ì ìˆ˜ë¥¼ ì œì‹œí•˜ì„¸ìš”
   - ìœ ì‚¬ ë‰´ìŠ¤ ê°œìˆ˜ ë° ìœ ì‚¬ë„ (ë†’ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ìƒìŠ¹)
   - ê³¼ê±° íŒ¨í„´ì˜ ì¼ê´€ì„± (ë³€ë™í­ì´ ì¼ì •í• ìˆ˜ë¡ ì‹ ë¢°ë„ ìƒìŠ¹)
   - ê³µì‹œ ì •ë³´ ìœ ë¬´ (ê³µì‹œê°€ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ìƒìŠ¹)
4. **ê·¼ê±°**: ì˜ˆì¸¡ ê·¼ê±°ë¥¼ **êµ¬ì²´ì  ìˆ˜ì¹˜**ì™€ í•¨ê»˜ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”

**ì‘ë‹µ í˜•ì‹** (JSON):
```json
{{
  "prediction": "ìƒìŠ¹" | "í•˜ë½" | "ìœ ì§€",
  "confidence": 75,
  "confidence_breakdown": {{
    "similar_news_quality": 85,
    "pattern_consistency": 70,
    "disclosure_impact": 60,
    "explanation": "ì‹ ë¢°ë„ ê³„ì‚° ê·¼ê±° ì„¤ëª…"
  }},
  "reasoning": "ì˜ˆì¸¡ ê·¼ê±° ì„¤ëª… (êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨)",
  "pattern_analysis": {{
    "avg_1d": 2.5,
    "avg_3d": 5.3,
    "avg_5d": 7.8,
    "max_1d": 4.2,
    "min_1d": 0.8
  }},
  "short_term": "ë‹¨ê¸°ì ìœ¼ë¡œ 2.5% ìƒìŠ¹ ì˜ˆìƒ",
  "medium_term": "ì¤‘ê¸°ì ìœ¼ë¡œ 5.3% ìƒìŠ¹ ì˜ˆìƒ",
  "long_term": "ì¥ê¸°ì ìœ¼ë¡œ 7.8% ìƒìŠ¹ ì˜ˆìƒ"
}}
```

**ì¤‘ìš” ì§€ì¹¨**:
- **confidence_breakdown**: ê° ìš”ì†Œ(similar_news_quality, pattern_consistency, disclosure_impact)ë¥¼ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•˜ê³ , ê³„ì‚° ê·¼ê±°ë¥¼ explanationì— ì„¤ëª…í•˜ì„¸ìš”
- **pattern_analysis**: ìœ ì‚¬ ë‰´ìŠ¤ í†µê³„ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•˜ì—¬ avg_1d, avg_3d, avg_5d ë“±ì„ ì œì‹œí•˜ì„¸ìš”
- **reasoning**: "ê³¼ê±° 15ê±´ ì¤‘ 12ê±´ ìƒìŠ¹, í‰ê·  +7.2%" ê°™ì€ êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ í¬í•¨í•˜ì„¸ìš”
- short_term, medium_term, long_termì—ëŠ” **ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ í¼ì„¼íŠ¸(%)ë¥¼ í¬í•¨**í•˜ì„¸ìš”
- ìœ ì‚¬ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì‹ ë¢°ë„ë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ê³ , ë‰´ìŠ¤ ë‚´ìš©ë§Œìœ¼ë¡œ í•©ë¦¬ì ì¸ ìˆ˜ì¹˜ë¥¼ ì œì‹œí•˜ì„¸ìš”
"""
        return prompt.strip()

    def predict(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
        news_id: Optional[int] = None,
        use_cache: bool = True,
    ) -> Dict[str, Any]:
        """
        ë‰´ìŠ¤ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            news_id: ë‰´ìŠ¤ ID (ìºì‹±ìš©, ì„ íƒì‚¬í•­)
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ {
                "prediction": str,      # ìƒìŠ¹/í•˜ë½/ìœ ì§€
                "confidence": int,      # 0-100
                "reasoning": str,       # ì˜ˆì¸¡ ê·¼ê±°
                "short_term": str,      # 1ì¼ ì˜ˆì¸¡
                "medium_term": str,     # 3ì¼ ì˜ˆì¸¡
                "long_term": str,       # 5ì¼ ì˜ˆì¸¡
                "similar_count": int,   # ì°¸ê³ í•œ ìœ ì‚¬ ë‰´ìŠ¤ ê°œìˆ˜
                "model": str,           # ì‚¬ìš© ëª¨ë¸
                "timestamp": str,       # ì˜ˆì¸¡ ì‹œê°
                "cached": bool          # ìºì‹œì—ì„œ ì¡°íšŒí–ˆëŠ”ì§€ ì—¬ë¶€
            }
        """
        stock_code = current_news.get("stock_code")

        # 1. ìºì‹œ í™•ì¸
        if use_cache and news_id and stock_code:
            cached_result = self.cache.get(news_id, stock_code)
            if cached_result:
                logger.info(f"ìºì‹œëœ ì˜ˆì¸¡ ë°˜í™˜: news_id={news_id}")
                cached_result["cached"] = True
                return cached_result

        # 2. ìºì‹œ ë¯¸ìŠ¤ â†’ LLM ì˜ˆì¸¡ ìˆ˜í–‰
        try:
            # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(current_news, similar_news)

            logger.info(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹œì‘: {current_news.get('title', 'N/A')[:50]}...")

            # 2. GPT-4 í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
                max_tokens=1000,
                response_format={"type": "json_object"},  # JSON ì‘ë‹µ ê°•ì œ
            )

            # 3. ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content
            result = json.loads(result_text)

            # 4. ê²°ê³¼ ë³´ê°•
            result["similar_count"] = len(similar_news)
            result["model"] = self.model
            result["timestamp"] = datetime.now().isoformat()
            result["cached"] = False

            # 5. ì‹ ë¢°ë„ breakdownì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜ì„±)
            if "confidence_breakdown" not in result:
                result["confidence_breakdown"] = {
                    "similar_news_quality": result.get("confidence", 0),
                    "pattern_consistency": 0,
                    "disclosure_impact": 0,
                    "explanation": "êµ¬ ë²„ì „ ì‘ë‹µ (breakdown ì—†ìŒ)"
                }

            # 6. pattern_analysisê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜ì„±)
            if "pattern_analysis" not in result:
                result["pattern_analysis"] = {
                    "avg_1d": None,
                    "avg_3d": None,
                    "avg_5d": None,
                }

            # 7. ê²€ì¦
            if "prediction" not in result or "confidence" not in result:
                raise ValueError("ì˜ˆì¸¡ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜")

            # ì‹ ë¢°ë„ breakdown ë¡œê¹…
            breakdown = result.get("confidence_breakdown", {})
            logger.info(
                f"ì˜ˆì¸¡ ì™„ë£Œ: {result['prediction']} (ì‹ ë¢°ë„: {result['confidence']}%) - "
                f"ìœ ì‚¬ë„í’ˆì§ˆ: {breakdown.get('similar_news_quality', 'N/A')}, "
                f"íŒ¨í„´ì¼ê´€ì„±: {breakdown.get('pattern_consistency', 'N/A')}, "
                f"ê³µì‹œì˜í–¥: {breakdown.get('disclosure_impact', 'N/A')}"
            )

            # 6. ìºì‹œ ì €ì¥
            if use_cache and news_id and stock_code:
                self.cache.set(news_id, stock_code, result)
                logger.info(f"ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì €ì¥: news_id={news_id}")

            return result

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}", exc_info=True)
            return self._get_fallback_prediction("JSON íŒŒì‹± ì˜¤ë¥˜")

        except Exception as e:
            logger.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}", exc_info=True)
            return self._get_fallback_prediction(str(e))

    def _get_fallback_prediction(self, error_msg: str) -> Dict[str, Any]:
        """
        ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ

        Args:
            error_msg: ì˜¤ë¥˜ ë©”ì‹œì§€

        Returns:
            ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼
        """
        return {
            "prediction": "ìœ ì§€",
            "confidence": 0,
            "reasoning": f"ì˜ˆì¸¡ ì‹¤íŒ¨: {error_msg}",
            "short_term": "ì˜ˆì¸¡ ë¶ˆê°€",
            "medium_term": "ì˜ˆì¸¡ ë¶ˆê°€",
            "long_term": "ì˜ˆì¸¡ ë¶ˆê°€",
            "similar_count": 0,
            "model": self.model,
            "timestamp": datetime.now().isoformat(),
            "error": error_msg,
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_predictor: Optional[StockPredictor] = None


def get_predictor() -> StockPredictor:
    """
    StockPredictor ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        StockPredictor ì¸ìŠ¤í„´ìŠ¤
    """
    global _predictor
    if _predictor is None:
        _predictor = StockPredictor()
    return _predictor
