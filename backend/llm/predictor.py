"""
ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë“ˆ

ìœ ì‚¬ ë‰´ìŠ¤ ê¸°ë°˜ LLM ì£¼ê°€ ì˜ˆì¸¡ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""
import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta

from openai import OpenAI
from sqlalchemy.orm import Session

from backend.config import settings
from backend.llm.prediction_cache import get_prediction_cache
from backend.db.models.stock import StockPrice, Stock
from backend.db.models.news import NewsArticle
from backend.db.models.model import Model
from backend.db.models.ab_test_config import ABTestConfig
from backend.db.session import SessionLocal
from sqlalchemy import text


logger = logging.getLogger(__name__)


class StockPredictor:
    """LLM ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ í´ë˜ìŠ¤"""

    def __init__(self):
        """ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™”"""
        # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸
        if settings.LLM_PROVIDER == "openrouter":
            self.client = OpenAI(
                api_key=settings.OPENROUTER_API_KEY,
                base_url="https://openrouter.ai/api/v1",
                default_headers={
                    "HTTP-Referer": "https://craveny.ai",
                    "X-Title": "Craveny Stock Predictor",
                }
            )
            self.model = settings.OPENROUTER_MODEL
            logger.info(f"OpenRouter ëª¨ë¸ ì‚¬ìš©: {self.model}")
        else:
            self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
            self.model = settings.OPENAI_MODEL
            logger.info(f"OpenAI ëª¨ë¸ ì‚¬ìš©: {self.model}")

        self.cache = get_prediction_cache()

        # ë©€í‹°ëª¨ë¸: DBì—ì„œ í™œì„± ëª¨ë¸ ë¡œë“œ
        self.active_models = self._load_active_models()
        logger.info(f"âœ… í™œì„± ëª¨ë¸ {len(self.active_models)}ê°œ ë¡œë“œ ì™„ë£Œ")

        # ë ˆê±°ì‹œ A/B í…ŒìŠ¤íŠ¸ (í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜) - í•˜ìœ„ í˜¸í™˜ì„±
        if settings.AB_TEST_ENABLED:
            self.client_a = self._create_client(settings.MODEL_A_PROVIDER)
            self.model_a = settings.MODEL_A_NAME
            self.client_b = self._create_client(settings.MODEL_B_PROVIDER)
            self.model_b = settings.MODEL_B_NAME
            logger.info(f"A/B í…ŒìŠ¤íŠ¸ í™œì„±í™” (ë ˆê±°ì‹œ): Model A={self.model_a}, Model B={self.model_b}")

    def _create_client(self, provider: str) -> OpenAI:
        """í”„ë¡œë°”ì´ë”ë³„ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        if provider == "openrouter":
            return OpenAI(
                api_key=settings.OPENROUTER_API_KEY,
                base_url="https://openrouter.ai/api/v1",
                default_headers={
                    "HTTP-Referer": "https://craveny.ai",
                    "X-Title": "Craveny Stock Predictor",
                }
            )
        else:  # openai
            return OpenAI(api_key=settings.OPENAI_API_KEY)

    def _load_active_models(self) -> Dict[int, Dict[str, Any]]:
        """
        DBì—ì„œ í™œì„± ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Returns:
            {model_id: {"name": "...", "provider": "...", "model_identifier": "...", "client": OpenAI(...)}}
        """
        db = SessionLocal()
        try:
            models = db.query(Model).filter(Model.is_active == True).all()
            result = {}

            for model in models:
                client = self._create_client(model.provider)
                result[model.id] = {
                    "name": model.name,
                    "provider": model.provider,
                    "model_identifier": model.model_identifier,
                    "client": client,
                    "description": model.description,
                }
                logger.info(f"  ğŸ“Š Model loaded: {model.name} ({model.provider}/{model.model_identifier})")

            return result

        except Exception as e:
            logger.error(f"í™œì„± ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
        finally:
            db.close()

    def _save_model_prediction(
        self,
        news_id: int,
        model_id: int,
        stock_code: str,
        prediction_data: Dict[str, Any]
    ) -> None:
        """
        ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ predictions í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            news_id: ë‰´ìŠ¤ ID
            model_id: ëª¨ë¸ ID
            stock_code: ì¢…ëª© ì½”ë“œ
            prediction_data: ì˜ˆì¸¡ ê²°ê³¼
        """
        db = SessionLocal()
        try:
            from backend.db.models.prediction import Prediction

            # ê¸°ì¡´ ì˜ˆì¸¡ì´ ìˆëŠ”ì§€ í™•ì¸
            existing = db.query(Prediction).filter(
                Prediction.news_id == news_id,
                Prediction.model_id == model_id
            ).first()

            # prediction_dataì—ì„œ í•„ë“œ ì¶”ì¶œ
            direction = prediction_data.get("direction", "hold")
            confidence = prediction_data.get("confidence", 0.5)
            reasoning = prediction_data.get("reasoning", "")
            current_price = prediction_data.get("current_price")
            short_term = prediction_data.get("short_term")
            medium_term = prediction_data.get("medium_term")
            long_term = prediction_data.get("long_term")
            confidence_breakdown = prediction_data.get("confidence_breakdown")
            pattern_analysis = prediction_data.get("pattern_analysis")

            if existing:
                # UPDATE
                existing.direction = direction
                existing.confidence = confidence
                existing.reasoning = reasoning
                existing.current_price = current_price
                existing.short_term = short_term
                existing.medium_term = medium_term
                existing.long_term = long_term
                existing.confidence_breakdown = confidence_breakdown
                existing.pattern_analysis = pattern_analysis
                existing.created_at = datetime.now()
            else:
                # INSERT
                new_prediction = Prediction(
                    news_id=news_id,
                    model_id=model_id,
                    stock_code=stock_code,
                    direction=direction,
                    confidence=confidence,
                    reasoning=reasoning,
                    current_price=current_price,
                    short_term=short_term,
                    medium_term=medium_term,
                    long_term=long_term,
                    confidence_breakdown=confidence_breakdown,
                    pattern_analysis=pattern_analysis,
                )
                db.add(new_prediction)

            db.commit()
            logger.debug(f"ëª¨ë¸ {model_id} ì˜ˆì¸¡ ì €ì¥ ì™„ë£Œ: news_id={news_id}, direction={direction}, confidence={confidence:.2f}")

        except Exception as e:
            logger.error(f"ëª¨ë¸ ì˜ˆì¸¡ ì €ì¥ ì‹¤íŒ¨ (news_id={news_id}, model_id={model_id}): {e}", exc_info=True)
            db.rollback()
        finally:
            db.close()

    def _get_prediction_from_db(
        self,
        news_id: int,
        model_id: int
    ) -> Optional[Dict[str, Any]]:
        """
        predictions í…Œì´ë¸”ì—ì„œ íŠ¹ì • ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            news_id: ë‰´ìŠ¤ ID
            model_id: ëª¨ë¸ ID

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë˜ëŠ” None
        """
        db = SessionLocal()
        try:
            from backend.db.models.prediction import Prediction

            prediction = db.query(Prediction).filter(
                Prediction.news_id == news_id,
                Prediction.model_id == model_id
            ).first()

            if not prediction:
                return None

            # Prediction ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            return {
                "direction": prediction.direction,
                "confidence": prediction.confidence,
                "reasoning": prediction.reasoning,
                "current_price": prediction.current_price,
                "short_term": prediction.short_term,
                "medium_term": prediction.medium_term,
                "long_term": prediction.long_term,
                "confidence_breakdown": prediction.confidence_breakdown,
                "pattern_analysis": prediction.pattern_analysis,
                "created_at": prediction.created_at.isoformat() if prediction.created_at else None,
            }

        except Exception as e:
            logger.error(f"ëª¨ë¸ ì˜ˆì¸¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            db.close()

    def _get_active_ab_config(self) -> Optional[ABTestConfig]:
        """í˜„ì¬ í™œì„±í™”ëœ A/B ì„¤ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        db = SessionLocal()
        try:
            config = db.query(ABTestConfig).filter(ABTestConfig.is_active == True).first()
            return config
        except Exception as e:
            logger.error(f"A/B ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            db.close()

    def _get_stock_info(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        ì¢…ëª© ê¸°ë³¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ

        Returns:
            ì¢…ëª© ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        db = SessionLocal()
        try:
            stock = db.query(Stock).filter(Stock.code == stock_code).first()
            if not stock:
                return None

            return {
                "code": stock.code,
                "name": stock.name,
                "priority": stock.priority,
            }
        except Exception as e:
            logger.error(f"ì¢…ëª© ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ (ì¢…ëª©ì½”ë“œ: {stock_code}): {e}")
            return None
        finally:
            db.close()

    def _get_current_stock_info(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        í˜„ì¬ ì£¼ê°€ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ

        Returns:
            ì£¼ê°€ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
            {
                "close": ì¢…ê°€,
                "open": ì‹œê°€,
                "high": ê³ ê°€,
                "low": ì €ê°€,
                "volume": ê±°ë˜ëŸ‰,
                "change_rate": ì „ì¼ ëŒ€ë¹„ ë³€ë™ë¥  (%),
                "date": ë‚ ì§œ
            }
        """
        db = SessionLocal()
        try:
            # ìµœê·¼ 2ì¼ ë°ì´í„° ì¡°íšŒ (ë³€ë™ë¥  ê³„ì‚°ìš©)
            recent_prices = (
                db.query(StockPrice)
                .filter(StockPrice.stock_code == stock_code)
                .order_by(StockPrice.date.desc())
                .limit(2)
                .all()
            )

            if not recent_prices:
                return None

            current = recent_prices[0]

            # ë³€ë™ë¥  ê³„ì‚°
            change_rate = 0.0
            if len(recent_prices) >= 2:
                previous = recent_prices[1]
                if previous.close > 0:
                    change_rate = ((current.close - previous.close) / previous.close) * 100

            return {
                "close": current.close,
                "open": current.open,
                "high": current.high,
                "low": current.low,
                "volume": current.volume,
                "change_rate": round(change_rate, 2),
                "date": current.date.strftime("%Y-%m-%d %H:%M") if current.date else "N/A",
            }

        except Exception as e:
            logger.error(f"í˜„ì¬ ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨ (ì¢…ëª©ì½”ë“œ: {stock_code}): {e}")
            return None
        finally:
            db.close()

    def _get_recent_disclosures(self, stock_code: str, days: int = 7) -> List[Dict[str, Any]]:
        """
        ìµœê·¼ DART ê³µì‹œ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            days: ì¡°íšŒí•  ê¸°ê°„ (ì¼)

        Returns:
            ê³µì‹œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        db = SessionLocal()
        try:
            since_date = datetime.now() - timedelta(days=days)

            disclosures = (
                db.query(NewsArticle)
                .filter(
                    NewsArticle.stock_code == stock_code,
                    NewsArticle.source == "dart",
                    NewsArticle.published_at >= since_date
                )
                .order_by(NewsArticle.published_at.desc())
                .limit(5)
                .all()
            )

            return [
                {
                    "title": disc.title,
                    "published_at": disc.published_at.strftime("%Y-%m-%d"),
                    "content": disc.content[:100] + "..." if len(disc.content) > 100 else disc.content,
                }
                for disc in disclosures
            ]

        except Exception as e:
            logger.error(f"DART ê³µì‹œ ì¡°íšŒ ì‹¤íŒ¨ (ì¢…ëª©ì½”ë“œ: {stock_code}): {e}")
            return []
        finally:
            db.close()

    def _get_market_context(self) -> Dict[str, Any]:
        """
        ì‹œì¥ ì§€ìˆ˜ ë§¥ë½ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Returns:
            ì‹œì¥ ì§€ìˆ˜ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        db = SessionLocal()
        try:
            from sqlalchemy import text

            # KOSPI ìµœì‹  ë°ì´í„°
            kospi_result = db.execute(
                text("""
                    SELECT close, change_pct, date
                    FROM market_indices
                    WHERE index_name = 'KOSPI'
                    ORDER BY date DESC
                    LIMIT 1
                """)
            )
            kospi_row = kospi_result.fetchone()

            # KOSDAQ ìµœì‹  ë°ì´í„°
            kosdaq_result = db.execute(
                text("""
                    SELECT close, change_pct, date
                    FROM market_indices
                    WHERE index_name = 'KOSDAQ'
                    ORDER BY date DESC
                    LIMIT 1
                """)
            )
            kosdaq_row = kosdaq_result.fetchone()

            return {
                "kospi": {
                    "close": round(kospi_row[0], 2) if kospi_row else None,
                    "change_pct": round(kospi_row[1], 2) if kospi_row else None,
                    "date": kospi_row[2].strftime("%Y-%m-%d") if kospi_row else None,
                } if kospi_row else None,
                "kosdaq": {
                    "close": round(kosdaq_row[0], 2) if kosdaq_row else None,
                    "change_pct": round(kosdaq_row[1], 2) if kosdaq_row else None,
                    "date": kosdaq_row[2].strftime("%Y-%m-%d") if kosdaq_row else None,
                } if kosdaq_row else None,
            }

        except Exception as e:
            logger.error(f"ì‹œì¥ ì§€ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"kospi": None, "kosdaq": None}
        finally:
            db.close()

    def _calculate_similar_news_stats(self, similar_news: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ìœ ì‚¬ ë‰´ìŠ¤ íŒ¨í„´ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

        Args:
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not similar_news:
            return {
                "count": 0,
                "avg_similarity": 0.0,
                "pattern_stats": {"1d": {}, "2d": {}, "3d": {}, "5d": {}, "10d": {}, "20d": {}},
            }

        # ìœ ì‚¬ë„ í‰ê·  ê³„ì‚°
        similarities = [news.get("similarity", 0) for news in similar_news]
        avg_similarity = sum(similarities) / len(similarities) if similarities else 0.0

        # ê° ê¸°ê°„ë³„ ë³€ë™ë¥  í†µê³„ (T+1, T+2, T+3, T+5, T+10, T+20)
        pattern_stats = {}
        for period in ["1d", "2d", "3d", "5d", "10d", "20d"]:
            changes = []
            for news in similar_news:
                price_info = news.get("price_changes", {})
                change = price_info.get(period)
                if change is not None and change != "N/A":
                    try:
                        changes.append(float(change))
                    except (ValueError, TypeError):
                        pass

            if changes:
                pattern_stats[period] = {
                    "avg": round(sum(changes) / len(changes), 2),
                    "max": round(max(changes), 2),
                    "min": round(min(changes), 2),
                    "count": len(changes),
                }
            else:
                pattern_stats[period] = {"avg": None, "max": None, "min": None, "count": 0}

        return {
            "count": len(similar_news),
            "avg_similarity": round(avg_similarity, 4),
            "pattern_stats": pattern_stats,
        }

    def _build_prompt(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
    ) -> str:
        """
        ì˜ˆì¸¡ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê°œì„  ë²„ì „)

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´ {title, content, stock_code}
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [{title, content, similarity, price_changes}]

        Returns:
            í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        stock_code = current_news.get('stock_code')

        # 1. ì¢…ëª© ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
        stock_basic = self._get_stock_info(stock_code) if stock_code else None
        stock_name = stock_basic['name'] if stock_basic else "ì•Œ ìˆ˜ ì—†ìŒ"

        # 2. ìœ ì‚¬ ë‰´ìŠ¤ í†µê³„ ê³„ì‚°
        similar_stats = self._calculate_similar_news_stats(similar_news)

        # 3. ìœ ì‚¬ ë‰´ìŠ¤ ìš”ì•½
        similar_cases = []
        for i, news in enumerate(similar_news, 1):
            price_info = news.get("price_changes", {})
            similar_cases.append(
                f"""
### ìœ ì‚¬ ì‚¬ë¡€ {i} (ìœ ì‚¬ë„: {news.get('similarity', 0):.2%})
**ì œëª©**: {news.get('news_title', 'N/A')}
**ë‚´ìš©**: {news.get('news_content', 'N/A')[:150]}...
**ë°œí‘œì¼**: {news.get('published_at', 'N/A')}
**ì£¼ê°€ ë³€ë™ë¥ **:
- T+1ì¼: {price_info.get('1d', 'N/A')}%, T+2ì¼: {price_info.get('2d', 'N/A')}%
- T+3ì¼: {price_info.get('3d', 'N/A')}%, T+5ì¼: {price_info.get('5d', 'N/A')}%
- T+10ì¼: {price_info.get('10d', 'N/A')}%, T+20ì¼: {price_info.get('20d', 'N/A')}%
"""
            )

        similar_section = "\n".join(similar_cases) if similar_cases else "ìœ ì‚¬ ë‰´ìŠ¤ ì—†ìŒ"

        # 4. ìœ ì‚¬ íŒ¨í„´ í†µê³„ ì„¹ì…˜
        pattern_stats = similar_stats['pattern_stats']
        stats_section = f"""
## ğŸ“Š ìœ ì‚¬ ë‰´ìŠ¤ íŒ¨í„´ í†µê³„ (ì´ {similar_stats['count']}ê±´, í‰ê·  ìœ ì‚¬ë„: {similar_stats['avg_similarity']:.1%})

"""
        for period, stats in pattern_stats.items():
            if stats.get('count', 0) > 0:
                stats_section += f"""**T+{period.replace('d', '')}ì¼**: í‰ê·  {stats['avg']:+.2f}%, ìµœëŒ€ {stats['max']:+.2f}%, ìµœì†Œ {stats['min']:+.2f}% (ë°ì´í„° {stats['count']}ê±´)
"""
            else:
                stats_section += f"""**T+{period.replace('d', '')}ì¼**: ë°ì´í„° ì—†ìŒ
"""

        # 5. í˜„ì¬ ì£¼ê°€ ì •ë³´ ì¡°íšŒ
        stock_price = self._get_current_stock_info(stock_code) if stock_code else None

        # 6. í˜„ì¬ ì£¼ê°€ ì •ë³´ ì„¹ì…˜
        if stock_price:
            change_indicator = "ğŸ“ˆ" if stock_price["change_rate"] > 0 else "ğŸ“‰" if stock_price["change_rate"] < 0 else "â¡ï¸"
            price_section = f"""
## í˜„ì¬ ì£¼ê°€ ì •ë³´ ({stock_price['date']})
**í˜„ì¬ê°€**: {stock_price['close']:,.0f}ì› ({change_indicator} {stock_price['change_rate']:+.2f}%)
**ë‹¹ì¼ ë³€ë™**: ì‹œê°€ {stock_price['open']:,.0f}ì› / ê³ ê°€ {stock_price['high']:,.0f}ì› / ì €ê°€ {stock_price['low']:,.0f}ì›
**ê±°ë˜ëŸ‰**: {stock_price['volume']:,}ì£¼

**âš ï¸ ì¤‘ìš”**: ì´ ì£¼ê°€ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì„¸ìš”.
- ìµœê·¼ ì£¼ê°€ íë¦„ì´ ìƒìŠ¹ì„¸ë¼ë©´ ê¸ì •ì  ë‰´ìŠ¤ì˜ ì˜í–¥ì´ ë” í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ìµœê·¼ ì£¼ê°€ê°€ í•˜ë½ì„¸ë¼ë©´ ë¶€ì •ì  ë‰´ìŠ¤ì˜ ì˜í–¥ì„ ë” ì‹ ì¤‘íˆ í‰ê°€í•˜ì„¸ìš”
"""
        else:
            price_section = "\n## í˜„ì¬ ì£¼ê°€ ì •ë³´\ní˜„ì¬ ì£¼ê°€ ì •ë³´ ì—†ìŒ\n"

        # 7. ìµœê·¼ DART ê³µì‹œ ì •ë³´ ì¡°íšŒ
        disclosures = self._get_recent_disclosures(stock_code, days=7) if stock_code else []

        if disclosures:
            disclosure_section = f"""
## ğŸ“¢ ìµœê·¼ 7ì¼ ê³µì‹œ ì •ë³´ ({len(disclosures)}ê±´)
"""
            for i, disc in enumerate(disclosures, 1):
                disclosure_section += f"""**{i}. [{disc['published_at']}] {disc['title']}**
ë‚´ìš©: {disc['content']}

"""
        else:
            disclosure_section = "\n## ğŸ“¢ ìµœê·¼ ê³µì‹œ ì •ë³´\nìµœê·¼ 7ì¼ ë‚´ ê³µì‹œ ì—†ìŒ\n"

        # 8. ì‹œì¥ ì§€ìˆ˜ ë§¥ë½ ì •ë³´ ì¡°íšŒ
        market_context = self._get_market_context()

        market_section = "\n## ğŸ“ˆ ì‹œì¥ ì§€ìˆ˜ í˜„í™©\n"
        if market_context.get("kospi"):
            kospi = market_context["kospi"]
            indicator = "ğŸ“ˆ" if kospi["change_pct"] > 0 else "ğŸ“‰" if kospi["change_pct"] < 0 else "â¡ï¸"
            market_section += f"""**KOSPI**: {kospi['close']:,.2f} ({indicator} {kospi['change_pct']:+.2f}%) - {kospi['date']}
"""
        if market_context.get("kosdaq"):
            kosdaq = market_context["kosdaq"]
            indicator = "ğŸ“ˆ" if kosdaq["change_pct"] > 0 else "ğŸ“‰" if kosdaq["change_pct"] < 0 else "â¡ï¸"
            market_section += f"""**KOSDAQ**: {kosdaq['close']:,.2f} ({indicator} {kosdaq['change_pct']:+.2f}%) - {kosdaq['date']}
"""
        if not market_context.get("kospi") and not market_context.get("kosdaq"):
            market_section += "ì‹œì¥ ì§€ìˆ˜ ì •ë³´ ì—†ìŒ\n"

        market_section += """
**âš ï¸ ì‹œì¥ ë§¥ë½ ê³ ë ¤ì‚¬í•­**:
- ì‹œì¥ ì „ì²´ê°€ ìƒìŠ¹ì„¸ë¼ë©´ ê°œë³„ ì¢…ëª©ì˜ ê¸ì •ì  ë‰´ìŠ¤ ì˜í–¥ì´ ì¦í­ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ì‹œì¥ì´ í•˜ë½ì„¸ë¼ë©´ ë¶€ì •ì  ë‰´ìŠ¤ì˜ ì˜í–¥ì´ ë” í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
"""

        # 9. ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ **ì¢…í•© íˆ¬ì ì–´ë“œë°”ì´ì €**ì…ë‹ˆë‹¤.
ë‰´ìŠ¤, ê³µì‹œ, ê³¼ê±° íŒ¨í„´, í˜„ì¬ ì£¼ê°€ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ì„ ì œê³µí•˜ì„¸ìš”.

---

## í˜„ì¬ ë‰´ìŠ¤
**ì¢…ëª©**: {stock_name} ({stock_code})
**ì œëª©**: {current_news.get('title', 'N/A')}
**ë‚´ìš©**: {current_news.get('content', 'N/A')[:300]}...

---
{price_section}
---
{market_section}
---
{disclosure_section}
---
{stats_section}
---

## ìœ ì‚¬í•œ ê³¼ê±° ë‰´ìŠ¤ì™€ ì‹¤ì œ ì£¼ê°€ ë³€ë™
{similar_section}

---

## ë¶„ì„ ìš”ì²­ì‚¬í•­

1. **íŒ¨í„´ ë¶„ì„**: ìœ„ í†µê³„ë¥¼ ì°¸ê³ í•˜ì—¬ ìœ ì‚¬ ë‰´ìŠ¤ë“¤ì˜ ì£¼ê°€ ë³€ë™ íŒ¨í„´ì„ ë¶„ì„í•˜ì„¸ìš”
2. **ì˜ˆì¸¡**: í˜„ì¬ ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹  ì˜í–¥ì„ ì˜ˆì¸¡í•˜ì„¸ìš” (ìƒìŠ¹/í•˜ë½/ìœ ì§€)
3. **ì‹ ë¢°ë„ ê³„ì‚°**: ë‹¤ìŒ ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ê³„ì‚°í•˜ê³ , ê° ìš”ì†Œì˜ ì ìˆ˜ë¥¼ ì œì‹œí•˜ì„¸ìš”
   - ìœ ì‚¬ ë‰´ìŠ¤ ê°œìˆ˜ ë° ìœ ì‚¬ë„ (ë†’ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ìƒìŠ¹)
   - ê³¼ê±° íŒ¨í„´ì˜ ì¼ê´€ì„± (ë³€ë™í­ì´ ì¼ì •í• ìˆ˜ë¡ ì‹ ë¢°ë„ ìƒìŠ¹)
   - ê³µì‹œ ì •ë³´ ìœ ë¬´ (ê³µì‹œê°€ ìˆìœ¼ë©´ ì‹ ë¢°ë„ ìƒìŠ¹)
4. **ê·¼ê±°**: ì˜ˆì¸¡ ê·¼ê±°ë¥¼ **êµ¬ì²´ì  ìˆ˜ì¹˜**ì™€ í•¨ê»˜ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”

**ì‘ë‹µ í˜•ì‹** (JSON):
```json
{{
  "prediction": "ìƒìŠ¹" | "í•˜ë½" | "ìœ ì§€",
  "confidence": 75,
  "confidence_breakdown": {{
    "similar_news_quality": 85,
    "pattern_consistency": 70,
    "disclosure_impact": 60,
    "explanation": "ì‹ ë¢°ë„ ê³„ì‚° ê·¼ê±° ì„¤ëª…"
  }},
  "reasoning": "ì˜ˆì¸¡ ê·¼ê±° ì„¤ëª… (êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨)",
  "pattern_analysis": {{
    "avg_1d": 2.5,
    "avg_3d": 5.3,
    "avg_5d": 7.8,
    "max_1d": 4.2,
    "min_1d": 0.8
  }},
  "short_term": "ë‹¨ê¸°ì ìœ¼ë¡œ 2.5% ìƒìŠ¹ ì˜ˆìƒ",
  "medium_term": "ì¤‘ê¸°ì ìœ¼ë¡œ 5.3% ìƒìŠ¹ ì˜ˆìƒ",
  "long_term": "ì¥ê¸°ì ìœ¼ë¡œ 7.8% ìƒìŠ¹ ì˜ˆìƒ"
}}
```

**ì¤‘ìš” ì§€ì¹¨**:
- **confidence_breakdown**: ê° ìš”ì†Œ(similar_news_quality, pattern_consistency, disclosure_impact)ë¥¼ 0-100 ì ìˆ˜ë¡œ í‰ê°€í•˜ê³ , ê³„ì‚° ê·¼ê±°ë¥¼ explanationì— ì„¤ëª…í•˜ì„¸ìš”
- **pattern_analysis**: ìœ ì‚¬ ë‰´ìŠ¤ í†µê³„ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•˜ì—¬ avg_1d, avg_3d, avg_5d ë“±ì„ ì œì‹œí•˜ì„¸ìš”
- **reasoning**: "ê³¼ê±° 15ê±´ ì¤‘ 12ê±´ ìƒìŠ¹, í‰ê·  +7.2%" ê°™ì€ êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ í¬í•¨í•˜ì„¸ìš”
- short_term, medium_term, long_termì—ëŠ” **ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ í¼ì„¼íŠ¸(%)ë¥¼ í¬í•¨**í•˜ì„¸ìš”
- ìœ ì‚¬ ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ì‹ ë¢°ë„ë¥¼ ë‚®ê²Œ ì„¤ì •í•˜ê³ , ë‰´ìŠ¤ ë‚´ìš©ë§Œìœ¼ë¡œ í•©ë¦¬ì ì¸ ìˆ˜ì¹˜ë¥¼ ì œì‹œí•˜ì„¸ìš”
"""
        return prompt.strip()

    def predict(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
        news_id: Optional[int] = None,
        use_cache: bool = True,
    ) -> Dict[str, Any]:
        """
        ë‰´ìŠ¤ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            news_id: ë‰´ìŠ¤ ID (ìºì‹±ìš©, ì„ íƒì‚¬í•­)
            use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ {
                "prediction": str,      # ìƒìŠ¹/í•˜ë½/ìœ ì§€
                "confidence": int,      # 0-100
                "reasoning": str,       # ì˜ˆì¸¡ ê·¼ê±°
                "short_term": str,      # 1ì¼ ì˜ˆì¸¡
                "medium_term": str,     # 3ì¼ ì˜ˆì¸¡
                "long_term": str,       # 5ì¼ ì˜ˆì¸¡
                "similar_count": int,   # ì°¸ê³ í•œ ìœ ì‚¬ ë‰´ìŠ¤ ê°œìˆ˜
                "model": str,           # ì‚¬ìš© ëª¨ë¸
                "timestamp": str,       # ì˜ˆì¸¡ ì‹œê°
                "cached": bool          # ìºì‹œì—ì„œ ì¡°íšŒí–ˆëŠ”ì§€ ì—¬ë¶€
            }
        """
        stock_code = current_news.get("stock_code")

        # 1. ìºì‹œ í™•ì¸
        if use_cache and news_id and stock_code:
            cached_result = self.cache.get(news_id, stock_code)
            if cached_result:
                logger.info(f"ìºì‹œëœ ì˜ˆì¸¡ ë°˜í™˜: news_id={news_id}")
                cached_result["cached"] = True
                return cached_result

        # 2. ìºì‹œ ë¯¸ìŠ¤ â†’ LLM ì˜ˆì¸¡ ìˆ˜í–‰
        try:
            # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(current_news, similar_news)

            logger.info(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹œì‘: {current_news.get('title', 'N/A')[:50]}...")

            # 2. LLM í˜¸ì¶œ (OpenRouterëŠ” JSON mode ë¯¸ì§€ì›)
            if settings.LLM_PROVIDER == "openrouter":
                # OpenRouter: JSON mode ì—†ì´ í˜¸ì¶œ, ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1000,
                )
            else:
                # OpenAI: JSON mode ì‚¬ìš©
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1000,
                    response_format={"type": "json_object"},
                )

            # 3. ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content

            # OpenRouter ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (```json ... ``` í˜•ì‹ì¼ ìˆ˜ ìˆìŒ)
            if settings.LLM_PROVIDER == "openrouter" and "```json" in result_text:
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_text, re.DOTALL)
                if json_match:
                    result_text = json_match.group(1)

            result = json.loads(result_text)

            # 4. ê²°ê³¼ ë³´ê°•
            result["similar_count"] = len(similar_news)
            result["model"] = self.model
            result["timestamp"] = datetime.now().isoformat()
            result["cached"] = False

            # 5. ì‹ ë¢°ë„ breakdownì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜ì„±)
            if "confidence_breakdown" not in result:
                result["confidence_breakdown"] = {
                    "similar_news_quality": result.get("confidence", 0),
                    "pattern_consistency": 0,
                    "disclosure_impact": 0,
                    "explanation": "êµ¬ ë²„ì „ ì‘ë‹µ (breakdown ì—†ìŒ)"
                }

            # 6. pattern_analysisê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì¶”ê°€ (í•˜ìœ„ í˜¸í™˜ì„±)
            if "pattern_analysis" not in result:
                result["pattern_analysis"] = {
                    "avg_1d": None,
                    "avg_3d": None,
                    "avg_5d": None,
                }

            # 7. ê²€ì¦
            if "prediction" not in result or "confidence" not in result:
                raise ValueError("ì˜ˆì¸¡ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜")

            # ì‹ ë¢°ë„ breakdown ë¡œê¹…
            breakdown = result.get("confidence_breakdown", {})
            logger.info(
                f"ì˜ˆì¸¡ ì™„ë£Œ: {result['prediction']} (ì‹ ë¢°ë„: {result['confidence']}%) - "
                f"ìœ ì‚¬ë„í’ˆì§ˆ: {breakdown.get('similar_news_quality', 'N/A')}, "
                f"íŒ¨í„´ì¼ê´€ì„±: {breakdown.get('pattern_consistency', 'N/A')}, "
                f"ê³µì‹œì˜í–¥: {breakdown.get('disclosure_impact', 'N/A')}"
            )

            # 6. ìºì‹œ ì €ì¥
            if use_cache and news_id and stock_code:
                self.cache.set(news_id, stock_code, result)
                logger.info(f"ì˜ˆì¸¡ ê²°ê³¼ ìºì‹œ ì €ì¥: news_id={news_id}")

            return result

        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}", exc_info=True)
            return self._get_fallback_prediction("JSON íŒŒì‹± ì˜¤ë¥˜")

        except Exception as e:
            logger.error(f"ì£¼ê°€ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}", exc_info=True)
            return self._get_fallback_prediction(str(e))

    def _get_fallback_prediction(self, error_msg: str) -> Dict[str, Any]:
        """
        ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ í´ë°± ì‘ë‹µ

        Args:
            error_msg: ì˜¤ë¥˜ ë©”ì‹œì§€

        Returns:
            ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼
        """
        return {
            "prediction": "ìœ ì§€",
            "confidence": 0,
            "reasoning": f"ì˜ˆì¸¡ ì‹¤íŒ¨: {error_msg}",
            "short_term": "ì˜ˆì¸¡ ë¶ˆê°€",
            "medium_term": "ì˜ˆì¸¡ ë¶ˆê°€",
            "long_term": "ì˜ˆì¸¡ ë¶ˆê°€",
            "similar_count": 0,
            "model": self.model,
            "timestamp": datetime.now().isoformat(),
            "error": error_msg,
        }

    def _predict_with_model(
        self,
        client: OpenAI,
        model_name: str,
        provider: str,
        prompt: str,
        similar_count: int,
    ) -> Dict[str, Any]:
        """
        íŠ¹ì • ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ (ë‚´ë¶€ í—¬í¼ ë©”ì„œë“œ)

        Args:
            client: OpenAI í´ë¼ì´ì–¸íŠ¸
            model_name: ëª¨ë¸ ì´ë¦„
            provider: í”„ë¡œë°”ì´ë” (openai/openrouter)
            prompt: ì˜ˆì¸¡ í”„ë¡¬í”„íŠ¸
            similar_count: ìœ ì‚¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            # LLM í˜¸ì¶œ
            if provider == "openrouter":
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1000,
                )
            else:  # openai
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1000,
                    response_format={"type": "json_object"},
                )

            # ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content

            # OpenRouter ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            if provider == "openrouter" and "```json" in result_text:
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_text, re.DOTALL)
                if json_match:
                    result_text = json_match.group(1)

            result = json.loads(result_text)

            # ê²°ê³¼ ë³´ê°•
            result["similar_count"] = similar_count
            result["model"] = model_name
            result["provider"] = provider
            result["timestamp"] = datetime.now().isoformat()

            # í•˜ìœ„ í˜¸í™˜ì„± ì²˜ë¦¬
            if "confidence_breakdown" not in result:
                result["confidence_breakdown"] = {
                    "similar_news_quality": result.get("confidence", 0),
                    "pattern_consistency": 0,
                    "disclosure_impact": 0,
                    "explanation": "êµ¬ ë²„ì „ ì‘ë‹µ"
                }
            if "pattern_analysis" not in result:
                result["pattern_analysis"] = {
                    "avg_1d": None,
                    "avg_3d": None,
                    "avg_5d": None,
                }

            return result

        except Exception as e:
            logger.error(f"ëª¨ë¸ {model_name} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                "prediction": "ìœ ì§€",
                "confidence": 0,
                "reasoning": f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}",
                "short_term": "ì˜ˆì¸¡ ë¶ˆê°€",
                "medium_term": "ì˜ˆì¸¡ ë¶ˆê°€",
                "long_term": "ì˜ˆì¸¡ ë¶ˆê°€",
                "similar_count": similar_count,
                "model": model_name,
                "provider": provider,
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
            }

    def dual_predict(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """
        A/B í…ŒìŠ¤íŠ¸: ë‘ ëª¨ë¸ë¡œ ë™ì‹œ ì˜ˆì¸¡

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

        Returns:
            A/B ë¹„êµ ê²°ê³¼
            {
                "ab_test_enabled": true,
                "model_a": {...},
                "model_b": {...},
                "comparison": {
                    "agreement": bool,
                    "confidence_diff": int,
                    "stronger_model": str
                }
            }
        """
        if not settings.AB_TEST_ENABLED:
            raise ValueError("A/B í…ŒìŠ¤íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")

        logger.info("ğŸ”¬ A/B í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ì‹œì‘")

        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ê³µí†µ)
        prompt = self._build_prompt(current_news, similar_news)
        similar_count = len(similar_news)

        # Model A ì˜ˆì¸¡
        logger.info(f"  ğŸ“Š Model A ({self.model_a}) ì˜ˆì¸¡ ì¤‘...")
        result_a = self._predict_with_model(
            self.client_a,
            self.model_a,
            settings.MODEL_A_PROVIDER,
            prompt,
            similar_count
        )

        # Model B ì˜ˆì¸¡
        logger.info(f"  ğŸ“Š Model B ({self.model_b}) ì˜ˆì¸¡ ì¤‘...")
        result_b = self._predict_with_model(
            self.client_b,
            self.model_b,
            settings.MODEL_B_PROVIDER,
            prompt,
            similar_count
        )

        # ë¹„êµ ë¶„ì„
        pred_a = result_a.get("prediction", "ìœ ì§€")
        pred_b = result_b.get("prediction", "ìœ ì§€")
        conf_a = result_a.get("confidence", 0)
        conf_b = result_b.get("confidence", 0)

        comparison = {
            "agreement": pred_a == pred_b,
            "confidence_diff": abs(conf_a - conf_b),
            "stronger_model": "model_a" if conf_a > conf_b else "model_b" if conf_b > conf_a else "tie",
            "prediction_match": pred_a == pred_b,
        }

        logger.info(f"  âœ… A/B í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì¼ì¹˜: {comparison['agreement']}, ì‹ ë¢°ë„ ì°¨ì´: {comparison['confidence_diff']}%")

        return {
            "ab_test_enabled": True,
            "model_a": result_a,
            "model_b": result_b,
            "comparison": comparison,
            "timestamp": datetime.now().isoformat(),
        }

    def predict_all_models(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
        news_id: int,
    ) -> Dict[int, Dict[str, Any]]:
        """
        ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìƒì„±í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            news_id: ë‰´ìŠ¤ ID

        Returns:
            {model_id: prediction_result, ...}
        """
        stock_code = current_news.get("stock_code")
        similar_count = len(similar_news)
        results = {}

        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ê³µí†µ)
        prompt = self._build_prompt(current_news, similar_news)

        logger.info(f"ğŸ”¬ ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì‹œì‘: news_id={news_id}, models={len(self.active_models)}")

        for model_id, model_info in self.active_models.items():
            logger.info(f"  ğŸ“Š {model_info['name']} ì˜ˆì¸¡ ì¤‘...")

            # ì˜ˆì¸¡ ì‹¤í–‰
            prediction = self._predict_with_model(
                model_info["client"],
                model_info["model_identifier"],
                model_info["provider"],
                prompt,
                similar_count
            )

            # ê²°ê³¼ì— model_id ì¶”ê°€
            prediction["model_id"] = model_id
            prediction["model"] = model_info["name"]

            # DB ì €ì¥
            self._save_model_prediction(news_id, model_id, stock_code, prediction)

            results[model_id] = prediction

        logger.info(f"âœ… ëª¨ë“  ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ")
        return results

    def get_ab_predictions(self, news_id: int) -> Dict[str, Any]:
        """
        í˜„ì¬ A/B ì„¤ì •ì— ë”°ë¼ ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            news_id: ë‰´ìŠ¤ ID

        Returns:
            {
                "model_a": {...},
                "model_b": {...},
                "comparison": {...}
            }
        """
        # í™œì„± A/B ì„¤ì • ì¡°íšŒ
        ab_config = self._get_active_ab_config()
        if not ab_config:
            logger.warning("í™œì„± A/B ì„¤ì • ì—†ìŒ")
            return {
                "error": "í™œì„± A/B ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤",
                "model_a": None,
                "model_b": None,
            }

        # ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì¡°íšŒ
        pred_a = self._get_prediction_from_db(news_id, ab_config.model_a_id)
        pred_b = self._get_prediction_from_db(news_id, ab_config.model_b_id)

        if not pred_a or not pred_b:
            logger.warning(f"ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ: model_a={pred_a is not None}, model_b={pred_b is not None}")
            return {
                "error": "ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € predict_all_models()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.",
                "model_a": pred_a,
                "model_b": pred_b,
            }

        # ë¹„êµ ë¶„ì„
        comparison = {
            "agreement": pred_a.get("prediction") == pred_b.get("prediction"),
            "confidence_diff": abs(pred_a.get("confidence", 0) - pred_b.get("confidence", 0)),
            "stronger_model": "model_a" if pred_a.get("confidence", 0) > pred_b.get("confidence", 0) else "model_b",
            "prediction_match": pred_a.get("prediction") == pred_b.get("prediction"),
        }

        return {
            "ab_test_enabled": True,  # í…”ë ˆê·¸ë¨ ì•Œë¦¼ í˜¸í™˜ì„±
            "model_a": pred_a,
            "model_b": pred_b,
            "comparison": comparison,
            "timestamp": datetime.now().isoformat(),
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_predictor: Optional[StockPredictor] = None


def get_predictor() -> StockPredictor:
    """
    StockPredictor ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        StockPredictor ì¸ìŠ¤í„´ìŠ¤
    """
    global _predictor
    if _predictor is None:
        _predictor = StockPredictor()
    return _predictor
