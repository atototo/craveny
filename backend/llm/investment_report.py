"""
LLM ê¸°ë°˜ ì¢…í•© íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë“ˆ

ì¢…ëª©ë³„ AI ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ íˆ¬ì ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
import logging
import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from openai import OpenAI

from backend.config import settings
from backend.db.models.prediction import Prediction
from backend.db.models.stock import StockPrice
from backend.utils.stock_mapping import get_stock_mapper


logger = logging.getLogger(__name__)


class InvestmentReportGenerator:
    """LLM ê¸°ë°˜ íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o-mini"  # ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸
        self.stock_mapper = get_stock_mapper()

        # A/B í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì¶”ê°€ í´ë¼ì´ì–¸íŠ¸
        if settings.AB_TEST_ENABLED:
            self.client_a = self._create_client(settings.MODEL_A_PROVIDER)
            self.model_a = settings.MODEL_A_NAME
            self.client_b = self._create_client(settings.MODEL_B_PROVIDER)
            self.model_b = settings.MODEL_B_NAME
            logger.info(f"A/B í…ŒìŠ¤íŠ¸ í™œì„±í™” (ì¢…í•© ë¦¬í¬íŠ¸): Model A={self.model_a}, Model B={self.model_b}")

    def _create_client(self, provider: str) -> OpenAI:
        """í”„ë¡œë°”ì´ë”ë³„ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        if provider == "openrouter":
            return OpenAI(
                api_key=settings.OPENROUTER_API_KEY,
                base_url="https://openrouter.ai/api/v1",
                default_headers={
                    "HTTP-Referer": "https://craveny.ai",
                    "X-Title": "Craveny Investment Report",
                }
            )
        else:  # openai
            return OpenAI(api_key=settings.OPENAI_API_KEY)

    def generate_report(
        self,
        stock_code: str,
        predictions: List[Prediction],
        current_price: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        ì¢…í•© íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            predictions: ìµœê·¼ ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 20ê±´)
            current_price: í˜„ì¬ ì£¼ê°€ ì •ë³´

        Returns:
            {
                "overall_summary": str,
                "short_term_scenario": str,
                "medium_term_scenario": str,
                "long_term_scenario": str,
                "risk_factors": List[str],
                "opportunity_factors": List[str],
                "recommendation": str,
            }
        """
        if not predictions:
            return self._empty_report()

        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            report_data = self._prepare_report_data(
                stock_code, predictions, current_price
            )

            # 2. LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._build_prompt(report_data)

            logger.info(f"íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘: {stock_code} ({len(predictions)}ê±´ ë¶„ì„)")

            # 3. LLM í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ë² í…Œë‘ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.4,  # ì ë‹¹í•œ ì°½ì˜ì„±
                max_tokens=1000,
                response_format={"type": "json_object"},  # JSON ì‘ë‹µ ê°•ì œ
            )

            # 4. ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content
            result = json.loads(result_text)

            logger.info(
                f"íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {stock_code} "
                f"(ì¶”ì²œ: {result.get('recommendation', 'N/A')[:30]}...)"
            )

            return result

        except Exception as e:
            logger.error(f"íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return self._empty_report()

    def _prepare_report_data(
        self,
        stock_code: str,
        predictions: List[Prediction],
        current_price: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        stock_name = self.stock_mapper.get_company_name(stock_code) or stock_code

        # í†µê³„ ê³„ì‚° - ìƒˆë¡œìš´ ì˜í–¥ë„ ë¶„ì„ í•„ë“œ ì‚¬ìš©
        total = len(predictions)

        # ê°ì„± ë°©í–¥ ë¶„í¬
        positive_count = sum(1 for p in predictions if p.sentiment_direction == "positive")
        negative_count = sum(1 for p in predictions if p.sentiment_direction == "negative")
        neutral_count = sum(1 for p in predictions if p.sentiment_direction == "neutral")

        # ì˜í–¥ë„ ë ˆë²¨ ë¶„í¬
        high_impact = sum(1 for p in predictions if p.impact_level == "high" or p.impact_level == "critical")
        medium_impact = sum(1 for p in predictions if p.impact_level == "medium")
        low_impact = sum(1 for p in predictions if p.impact_level == "low")

        # í‰ê·  ê°ì„± ì ìˆ˜ ë° ê´€ë ¨ì„± ì ìˆ˜
        sentiment_scores = [p.sentiment_score for p in predictions if p.sentiment_score is not None]
        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0

        relevance_scores = [p.relevance_score for p in predictions if p.relevance_score is not None]
        avg_relevance = sum(relevance_scores) / len(relevance_scores) if relevance_scores else 0

        # ì‹ ë¢°ë„ breakdown í‰ê· 
        breakdown_avg = {"similar_news_quality": None, "pattern_consistency": None, "disclosure_impact": None}
        breakdown_counts = {"similar_news_quality": 0, "pattern_consistency": 0, "disclosure_impact": 0}
        breakdown_sums = {"similar_news_quality": 0.0, "pattern_consistency": 0.0, "disclosure_impact": 0.0}

        for pred in predictions:
            if pred.confidence_breakdown:
                for key in ["similar_news_quality", "pattern_consistency", "disclosure_impact"]:
                    val = pred.confidence_breakdown.get(key)
                    if val is not None:
                        breakdown_sums[key] += val
                        breakdown_counts[key] += 1

        for key in ["similar_news_quality", "pattern_consistency", "disclosure_impact"]:
            if breakdown_counts[key] > 0:
                breakdown_avg[key] = round(breakdown_sums[key] / breakdown_counts[key], 1)

        # íŒ¨í„´ ë¶„ì„ í‰ê· 
        pattern_avg = {"avg_1d": None, "avg_3d": None, "avg_5d": None, "avg_10d": None, "avg_20d": None}
        pattern_counts = {"avg_1d": 0, "avg_3d": 0, "avg_5d": 0, "avg_10d": 0, "avg_20d": 0}
        pattern_sums = {"avg_1d": 0.0, "avg_3d": 0.0, "avg_5d": 0.0, "avg_10d": 0.0, "avg_20d": 0.0}

        for pred in predictions:
            if pred.pattern_analysis:
                for key in ["avg_1d", "avg_3d", "avg_5d", "avg_10d", "avg_20d"]:
                    val = pred.pattern_analysis.get(key)
                    if val is not None and val != 0.0:
                        pattern_sums[key] += val
                        pattern_counts[key] += 1

        for key in ["avg_1d", "avg_3d", "avg_5d", "avg_10d", "avg_20d"]:
            if pattern_counts[key] > 0:
                pattern_avg[key] = round(pattern_sums[key] / pattern_counts[key], 2)

        # ìµœê·¼ ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„ (ìµœëŒ€ 5ê±´)
        recent_news_analysis = []
        for pred in predictions[:5]:
            recent_news_analysis.append({
                "created_at": pred.created_at.strftime("%Y-%m-%d") if pred.created_at else "N/A",
                "sentiment_direction": pred.sentiment_direction or "neutral",
                "sentiment_score": round(pred.sentiment_score, 2) if pred.sentiment_score is not None else 0.0,
                "impact_level": pred.impact_level or "low",
                "relevance_score": round(pred.relevance_score, 2) if pred.relevance_score is not None else 0.0,
                "urgency_level": pred.urgency_level or "routine",
                "reasoning": pred.reasoning[:200] if pred.reasoning else "ë¶„ì„ ë‚´ìš© ì—†ìŒ",
                "impact_analysis": pred.impact_analysis if pred.impact_analysis else {},
            })

        # í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        from backend.llm.predictor import StockPredictor
        predictor = StockPredictor()
        technical_indicators = predictor._get_technical_indicators(stock_code)

        return {
            "stock_info": {
                "code": stock_code,
                "name": stock_name,
                "current_price": current_price.get("close") if current_price else None,
                "change_rate": current_price.get("change_rate") if current_price else None,
            },
            "statistical_summary": {
                "total_predictions": total,
                "sentiment_distribution": {
                    "positive": positive_count,
                    "negative": negative_count,
                    "neutral": neutral_count,
                },
                "impact_distribution": {
                    "high": high_impact,
                    "medium": medium_impact,
                    "low": low_impact,
                },
                "avg_sentiment_score": round(avg_sentiment, 2),
                "avg_relevance_score": round(avg_relevance, 2),
                "confidence_breakdown_avg": breakdown_avg,  # ë ˆê±°ì‹œ í˜¸í™˜ì„± ìœ ì§€
                "pattern_analysis_avg": pattern_avg,
            },
            "recent_news_analysis": recent_news_analysis,
            "technical_indicators": technical_indicators,  # í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
            "time_context": {
                "today": datetime.now().strftime("%Y-%m-%d"),
                "analysis_period": "ìµœê·¼ 30ì¼",
                "latest_analysis_date": predictions[0].created_at.strftime("%Y-%m-%d") if predictions[0].created_at else "N/A",
            },
        }

    def _build_prompt(self, data: Dict[str, Any]) -> str:
        """LLM í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        stock_info = data["stock_info"]
        stats = data["statistical_summary"]
        recent_news = data["recent_news_analysis"]
        time_ctx = data["time_context"]
        technical = data.get("technical_indicators")

        prompt = f"""
ë‹¹ì‹ ì€ {stock_info['name']}({stock_info['code']})ì— ëŒ€í•œ **ë°ì¼ë¦¬ íˆ¬ì ë¦¬í¬íŠ¸**ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

## í˜„ì¬ ìƒí™© ({time_ctx['today']})
- í˜„ì¬ê°€: {stock_info['current_price']:,}ì› (ì „ì¼ ëŒ€ë¹„ {stock_info['change_rate']:+.2f}%) {f"" if stock_info['current_price'] else "í˜„ì¬ê°€ ì •ë³´ ì—†ìŒ"}
- ë¶„ì„ ê¸°ê°„: {time_ctx['analysis_period']}
- ë¶„ì„ëœ ë‰´ìŠ¤: ì´ {stats['total_predictions']}ê±´

## ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„ ìš”ì•½
- ê°ì„± ë¶„í¬: ê¸ì • {stats['sentiment_distribution']['positive']}ê±´, ë¶€ì • {stats['sentiment_distribution']['negative']}ê±´, ì¤‘ë¦½ {stats['sentiment_distribution']['neutral']}ê±´
- ì˜í–¥ë„ ë¶„í¬: ë†’ìŒ {stats['impact_distribution']['high']}ê±´, ì¤‘ê°„ {stats['impact_distribution']['medium']}ê±´, ë‚®ìŒ {stats['impact_distribution']['low']}ê±´
- í‰ê·  ê°ì„± ì ìˆ˜: {stats['avg_sentiment_score']:.2f} (ë²”ìœ„: -1.0 ~ 1.0, ì–‘ìˆ˜=ê¸ì •)
- í‰ê·  ê´€ë ¨ì„±: {stats['avg_relevance_score']:.2f} (ë²”ìœ„: 0.0 ~ 1.0)

## ê³¼ê±° íŒ¨í„´ ë¶„ì„ (ìœ ì‚¬ ë‰´ìŠ¤ ê¸°ë°˜ í‰ê·  ë³€ë™ë¥ )
- T+1ì¼: {f"{stats['pattern_analysis_avg']['avg_1d']:+.1f}%" if stats['pattern_analysis_avg']['avg_1d'] is not None else 'N/A'}
- T+3ì¼: {f"{stats['pattern_analysis_avg']['avg_3d']:+.1f}%" if stats['pattern_analysis_avg']['avg_3d'] is not None else 'N/A'}
- T+5ì¼: {f"{stats['pattern_analysis_avg']['avg_5d']:+.1f}%" if stats['pattern_analysis_avg']['avg_5d'] is not None else 'N/A'}
- T+10ì¼: {f"{stats['pattern_analysis_avg']['avg_10d']:+.1f}%" if stats['pattern_analysis_avg']['avg_10d'] is not None else 'N/A'}
- T+20ì¼: {f"{stats['pattern_analysis_avg']['avg_20d']:+.1f}%" if stats['pattern_analysis_avg']['avg_20d'] is not None else 'N/A'}

{self._format_technical_indicators(technical) if technical else ""}

## ìµœê·¼ ì£¼ìš” AI ë¶„ì„ ({len(recent_news)}ê±´)
{self._format_recent_news(recent_news)}

---

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **íˆ¬ìì ê´€ì **ì—ì„œ ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

```json
{{
  "overall_summary": "í˜„ì¬ ì‹œì ì—ì„œ ì´ ì¢…ëª©ì— ëŒ€í•œ ì „ì²´ì ì¸ íŒë‹¨ (2-3ë¬¸ì¥, í•µì‹¬ë§Œ)",
  "short_term_scenario": "ë‹¨ê¸° íˆ¬ìì(1ì¼~1ì£¼) ê´€ì : êµ¬ì²´ì  ëª©í‘œê°€ì™€ ì†ì ˆê°€, ì§„ì…/ì²­ì‚° ì „ëµ",
  "medium_term_scenario": "ì¤‘ê¸° íˆ¬ìì(1ì£¼~1ê°œì›”) ê´€ì : êµ¬ì²´ì  ëª©í‘œê°€ì™€ ì „ëµ, ì˜ˆìƒ ìˆ˜ìµë¥ ",
  "long_term_scenario": "ì¥ê¸° íˆ¬ìì(1ê°œì›” ì´ìƒ) ê´€ì : ëª©í‘œê°€ì™€ ë³´ìœ  ì „ëµ, ë¶„í•  ë§¤ìˆ˜/ë§¤ë„ ê³„íš",
  "risk_factors": ["ë¦¬ìŠ¤í¬ ìš”ì¸ 1 (êµ¬ì²´ì )", "ë¦¬ìŠ¤í¬ ìš”ì¸ 2", "ë¦¬ìŠ¤í¬ ìš”ì¸ 3"],
  "opportunity_factors": ["ê¸°íšŒ ìš”ì¸ 1 (êµ¬ì²´ì )", "ê¸°íšŒ ìš”ì¸ 2", "ê¸°íšŒ ìš”ì¸ 3"],
  "recommendation": "ìµœì¢… ì¶”ì²œ: ëª…í™•í•œ ì•¡ì…˜(ë§¤ìˆ˜/ê´€ë§/ë§¤ë„) + ê°„ê²°í•œ ì´ìœ  (1-2ë¬¸ì¥)",
  "price_targets": {{
    "base_price": {stock_info['current_price']},
    "short_term_target": ìˆ«ìë§Œ (ëª©í‘œê°€),
    "short_term_support": ìˆ«ìë§Œ (ì†ì ˆê°€),
    "medium_term_target": ìˆ«ìë§Œ (ëª©í‘œê°€),
    "medium_term_support": ìˆ«ìë§Œ (ì†ì ˆê°€),
    "long_term_target": ìˆ«ìë§Œ (ëª©í‘œê°€)
  }}
}}
```

**ì¤‘ìš” ì§€ì¹¨**:
1. **ë‰´ìŠ¤ ì˜í–¥ë„ë¥¼ ê°€ê²© ì˜ˆì¸¡ì— ë°˜ì˜**: ê¸ì • ë‰´ìŠ¤ ë§ìœ¼ë©´ ìƒìŠ¹, ë¶€ì • ë‰´ìŠ¤ ë§ìœ¼ë©´ í•˜ë½ ì˜ˆìƒ
2. **ê¸°ìˆ ì  ì§€í‘œì™€ ê²°í•©**: ë‹¨ìˆœíˆ ë‰´ìŠ¤ë§Œì´ ì•„ë‹Œ, ê¸°ìˆ ì  ë¶„ì„ë„ í•¨ê»˜ ê³ ë ¤
3. êµ¬ì²´ì ì¸ **ìˆ˜ì¹˜ì™€ ê¸°ê°„**ì„ ëª…ì‹œ (ëª©í‘œê°€, ì†ì ˆê°€, ì˜ˆìƒ ìˆ˜ìµë¥ )
4. íˆ¬ììê°€ **ì˜¤ëŠ˜ ê²°ì •**ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ì‘ì„±
5. ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒëŠ” ê°ê° **ìµœëŒ€ 3ê°œ**ê¹Œì§€ë§Œ
6. **ê°„ê²°í•˜ê³  ëª…í™•**í•˜ê²Œ (ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°)
"""
        return prompt.strip()

    def _format_recent_news(self, recent_news: List[Dict[str, Any]]) -> str:
        """ìµœê·¼ ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„ í¬ë§·íŒ…"""
        lines = []
        for i, news in enumerate(recent_news, 1):
            sentiment_kr = {"positive": "ê¸ì •", "negative": "ë¶€ì •", "neutral": "ì¤‘ë¦½"}.get(news["sentiment_direction"], news["sentiment_direction"])
            impact_kr = {"high": "ë†’ìŒ", "critical": "ë§¤ìš° ë†’ìŒ", "medium": "ì¤‘ê°„", "low": "ë‚®ìŒ"}.get(news["impact_level"], news["impact_level"])
            urgency_kr = {"urgent": "ê¸´ê¸‰", "breaking": "ì†ë³´", "notable": "ì£¼ëª©", "routine": "ì¼ë°˜"}.get(news["urgency_level"], news["urgency_level"])

            # ì˜í–¥ë„ ë¶„ì„ ìš”ì•½
            impact_summary = news.get("impact_analysis", {})
            business_impact = impact_summary.get("business_impact", "")[:100] if impact_summary else ""

            lines.append(
                f"### {i}. {news['created_at']} - {sentiment_kr} ê°ì„± (ì˜í–¥ë„: {impact_kr}, ê¸´ê¸‰ë„: {urgency_kr})\n"
                f"- ê°ì„± ì ìˆ˜: {news['sentiment_score']:.2f} (ë²”ìœ„: -1.0 ~ 1.0)\n"
                f"- ê´€ë ¨ì„±: {news['relevance_score']:.2f}\n"
                f"- AI ë¶„ì„: {news['reasoning']}\n"
                f"{f'- ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥: {business_impact}...' if business_impact else ''}"
            )
        return "\n\n".join(lines)

    def _format_technical_indicators(self, technical: Dict[str, Any]) -> str:
        """ê¸°ìˆ ì  ì§€í‘œ í¬ë§·íŒ…"""
        if not technical:
            return ""

        sections = []

        # ì´ë™í‰ê· ì„  ë¶„ì„
        ma = technical.get("moving_averages")
        if ma:
            ma_trend = ma.get("trend", "ì¤‘ë¦½")
            sections.append(f"""## ğŸ“ˆ í˜„ì¬ ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„

### ì´ë™í‰ê· ì„  ({ma_trend})
- MA5: {ma.get('ma5', 0):,.0f}ì› (í˜„ì¬ê°€ ëŒ€ë¹„ {ma.get('current_vs_ma5', 0):+.1f}%)
- MA20: {ma.get('ma20', 0):,.0f}ì› (í˜„ì¬ê°€ ëŒ€ë¹„ {ma.get('current_vs_ma20', 0):+.1f}%)
- MA60: {ma.get('ma60', 0):,.0f}ì› (í˜„ì¬ê°€ ëŒ€ë¹„ {ma.get('current_vs_ma60', 0):+.1f}%)""")

        # ê±°ë˜ëŸ‰ ë¶„ì„
        vol = technical.get("volume_analysis")
        if vol:
            vol_trend = vol.get("trend", "ì¤‘ë¦½")
            sections.append(f"""### ê±°ë˜ëŸ‰ ë¶„ì„ ({vol_trend})
- ì˜¤ëŠ˜ ê±°ë˜ëŸ‰: {vol.get('current_volume', 0):,}ì£¼
- 20ì¼ í‰ê· : {vol.get('avg_volume_20d', 0):,.0f}ì£¼
- ê±°ë˜ëŸ‰ ë¹„ìœ¨: {vol.get('volume_ratio', 0):+.1f}%""")

        # RSI ë¶„ì„
        rsi = technical.get("rsi")
        if rsi and rsi.get("value") is not None:
            rsi_signal = rsi.get("signal", "ì¤‘ë¦½")
            rsi_emoji = "ğŸ”¥" if rsi_signal == "ê³¼ë§¤ìˆ˜" else "â„ï¸" if rsi_signal == "ê³¼ë§¤ë„" else "â¡ï¸"
            sections.append(f"""### RSI ë¶„ì„ ({rsi_emoji} {rsi_signal})
- RSI (14ì¼): {rsi.get('value', 0):.1f}
- í•´ì„: {self._get_rsi_interpretation(rsi.get('value', 50))}""")

        # ë³¼ë¦°ì € ë°´ë“œ ë¶„ì„
        bb = technical.get("bollinger_bands")
        if bb:
            bb_signal = bb.get("signal", "ì¤‘ë¦½")
            sections.append(f"""### ë³¼ë¦°ì € ë°´ë“œ ({bb_signal})
- ìƒë‹¨: {bb.get('upper', 0):,.0f}ì›
- ì¤‘ê°„ (MA20): {bb.get('middle', 0):,.0f}ì›
- í•˜ë‹¨: {bb.get('lower', 0):,.0f}ì›
- %B: {bb.get('percent_b', 0):.2f} (0=í•˜ë‹¨, 0.5=ì¤‘ê°„, 1=ìƒë‹¨)""")

        # MACD ë¶„ì„
        macd = technical.get("macd")
        if macd:
            macd_signal = macd.get("signal_type", "ì¤‘ë¦½")
            macd_emoji = "ğŸ“ˆ" if macd_signal == "ìƒìŠ¹" else "ğŸ“‰" if macd_signal == "í•˜ë½" else "â¡ï¸"
            sections.append(f"""### MACD ë¶„ì„ ({macd_emoji} {macd_signal})
- MACD: {macd.get('macd_line', 0):.2f}
- Signal: {macd.get('signal_line', 0):.2f}
- Histogram: {macd.get('histogram', 0):.2f}""")

        # ê°€ê²© ëª¨ë©˜í…€
        momentum = technical.get("price_momentum")
        if momentum:
            momentum_trend = momentum.get("trend", "ì¤‘ë¦½")
            sections.append(f"""### ê°€ê²© ëª¨ë©˜í…€ ({momentum_trend})
- 1ì¼ ìˆ˜ìµë¥ : {momentum.get('change_1d', 0):+.2f}%
- 5ì¼ ìˆ˜ìµë¥ : {momentum.get('change_5d', 0):+.2f}%
- 20ì¼ ìˆ˜ìµë¥ : {momentum.get('change_20d', 0):+.2f}%""")

        return "\n\n".join(sections)

    def _get_rsi_interpretation(self, rsi_value: float) -> str:
        """RSI ê°’ í•´ì„"""
        if rsi_value >= 70:
            return "ê³¼ë§¤ìˆ˜ êµ¬ê°„ - ë‹¨ê¸° ì¡°ì • ê°€ëŠ¥ì„±"
        elif rsi_value <= 30:
            return "ê³¼ë§¤ë„ êµ¬ê°„ - ë°˜ë“± ê°€ëŠ¥ì„±"
        else:
            return "ì¤‘ë¦½ êµ¬ê°„"

    def dual_generate_report(
        self,
        stock_code: str,
        predictions: List[Prediction],
        current_price: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        A/B í…ŒìŠ¤íŠ¸: ë‘ ëª¨ë¸ë¡œ ì¢…í•© íˆ¬ì ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            stock_code: ì¢…ëª© ì½”ë“œ
            predictions: ìµœê·¼ ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸
            current_price: í˜„ì¬ ì£¼ê°€ ì •ë³´

        Returns:
            {
                "ab_test_enabled": true,
                "model_a": {...},
                "model_b": {...},
                "comparison": {...}
            }
        """
        if not settings.AB_TEST_ENABLED:
            raise ValueError("A/B í…ŒìŠ¤íŠ¸ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")

        if not predictions:
            return {
                "ab_test_enabled": True,
                "model_a": self._empty_report(),
                "model_b": self._empty_report(),
                "comparison": {
                    "recommendation_match": False,
                    "risk_overlap": [],
                    "opportunity_overlap": [],
                }
            }

        try:
            # ê³µí†µ ë°ì´í„° ì¤€ë¹„
            report_data = self._prepare_report_data(stock_code, predictions, current_price)
            prompt = self._build_prompt(report_data)

            logger.info(f"A/B ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±: {stock_code} ({len(predictions)}ê±´ ë¶„ì„)")

            # Model A (GPT-4o) í˜¸ì¶œ
            response_a = self.client_a.chat.completions.create(
                model=self.model_a,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ë² í…Œë‘ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.4,
                max_tokens=1000,
                response_format={"type": "json_object"},
            )

            result_a = json.loads(response_a.choices[0].message.content)
            result_a["model"] = self.model_a
            result_a["provider"] = settings.MODEL_A_PROVIDER

            # Model B (DeepSeek) í˜¸ì¶œ
            response_b = self.client_b.chat.completions.create(
                model=self.model_b,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ë² í…Œë‘ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´ ì—†ì´ ìˆœìˆ˜ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ì„¸ìš”.",
                    },
                    {"role": "user", "content": prompt},
                ],
                temperature=0.4,
                max_tokens=1000,
            )

            result_b_text = response_b.choices[0].message.content

            # OpenRouter JSON ì¶”ì¶œ (ë” ê°•ë ¥í•œ ë¡œì§)
            if settings.MODEL_B_PROVIDER == "openrouter":
                import re

                # 1. ```json ``` ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ ì°¾ê¸°
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_b_text, re.DOTALL)
                if json_match:
                    result_b_text = json_match.group(1)
                # 2. ``` ``` ì¼ë°˜ ì½”ë“œ ë¸”ë¡ ì°¾ê¸°
                elif '```' in result_b_text:
                    json_match = re.search(r'```\s*(\{.*?\})\s*```', result_b_text, re.DOTALL)
                    if json_match:
                        result_b_text = json_match.group(1)
                # 3. JSON ê°ì²´ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì—†ì´)
                else:
                    json_match = re.search(r'(\{[^{]*"overall_summary".*?\})\s*$', result_b_text, re.DOTALL)
                    if json_match:
                        result_b_text = json_match.group(1)

            # JSON íŒŒì‹± ì‹œë„
            try:
                result_b = json.loads(result_b_text)
                result_b["model"] = self.model_b
                result_b["provider"] = settings.MODEL_B_PROVIDER
            except json.JSONDecodeError as e:
                logger.error(f"Model B JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {result_b_text[:500]}")

                # ë¹ˆ ë¦¬í¬íŠ¸ë¡œ ëŒ€ì²´
                result_b = self._empty_report()
                result_b["model"] = self.model_b
                result_b["provider"] = settings.MODEL_B_PROVIDER
                result_b["parse_error"] = f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}"

            # ë¹„êµ ë¶„ì„
            comparison = self._compare_reports(result_a, result_b)

            logger.info(
                f"A/B ì¢…í•© ë¦¬í¬íŠ¸ ì™„ë£Œ: {stock_code} - "
                f"ì¶”ì²œ ì¼ì¹˜: {comparison['recommendation_match']}"
            )

            return {
                "ab_test_enabled": True,
                "model_a": result_a,
                "model_b": result_b,
                "comparison": comparison,
            }

        except Exception as e:
            logger.error(f"A/B ì¢…í•© ë¦¬í¬íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
            return {
                "ab_test_enabled": True,
                "model_a": self._empty_report(),
                "model_b": self._empty_report(),
                "comparison": {"error": str(e)},
            }

    def _compare_reports(self, report_a: Dict[str, Any], report_b: Dict[str, Any]) -> Dict[str, Any]:
        """ë‘ ë¦¬í¬íŠ¸ ë¹„êµ"""
        # ì¶”ì²œ ì¼ì¹˜ ì—¬ë¶€
        rec_a = report_a.get("recommendation", "").lower()
        rec_b = report_b.get("recommendation", "").lower()

        recommendation_match = False
        if ("ë§¤ìˆ˜" in rec_a and "ë§¤ìˆ˜" in rec_b) or \
           ("ë§¤ë„" in rec_a and "ë§¤ë„" in rec_b) or \
           ("ê´€ë§" in rec_a and "ê´€ë§" in rec_b) or \
           ("ë³´ìœ " in rec_a and "ë³´ìœ " in rec_b):
            recommendation_match = True

        # ë¦¬ìŠ¤í¬ ì¤‘ë³µ
        risks_a = set(report_a.get("risk_factors", []))
        risks_b = set(report_b.get("risk_factors", []))
        risk_overlap = list(risks_a & risks_b)

        # ê¸°íšŒ ì¤‘ë³µ
        opps_a = set(report_a.get("opportunity_factors", []))
        opps_b = set(report_b.get("opportunity_factors", []))
        opportunity_overlap = list(opps_a & opps_b)

        return {
            "recommendation_match": recommendation_match,
            "risk_overlap": risk_overlap,
            "opportunity_overlap": opportunity_overlap,
        }

    def _empty_report(self) -> Dict[str, Any]:
        """ë¹ˆ ë¦¬í¬íŠ¸ ë°˜í™˜"""
        return {
            "overall_summary": "ë¶„ì„ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "short_term_scenario": None,
            "medium_term_scenario": None,
            "long_term_scenario": None,
            "risk_factors": [],
            "opportunity_factors": [],
            "recommendation": None,
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_generator: Optional[InvestmentReportGenerator] = None


def get_report_generator() -> InvestmentReportGenerator:
    """
    InvestmentReportGenerator ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Returns:
        InvestmentReportGenerator ì¸ìŠ¤í„´ìŠ¤
    """
    global _generator
    if _generator is None:
        _generator = InvestmentReportGenerator()
    return _generator
