"""
ë©€í‹° ëª¨ë¸ ì£¼ê°€ ì˜ˆì¸¡ ì‹œìŠ¤í…œ

ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìƒì„±í•˜ê³ , A/B ì„¤ì •ì— ë”°ë¼ í‘œì‹œí•  ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.
"""
import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime

from openai import OpenAI
from sqlalchemy.orm import Session
from sqlalchemy import text

from backend.config import settings
from backend.db.models.model import Model
from backend.db.models.ab_test_config import ABTestConfig
from backend.db.session import SessionLocal


logger = logging.getLogger(__name__)


class MultiModelPredictor:
    """ë©€í‹° ëª¨ë¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ"""

    def __init__(self):
        """í™œì„± ëª¨ë¸ ë¡œë“œ"""
        self.active_models = self._load_active_models()
        logger.info(f"âœ… í™œì„± ëª¨ë¸ {len(self.active_models)}ê°œ ë¡œë“œ ì™„ë£Œ")

    def _load_active_models(self) -> Dict[int, Dict[str, Any]]:
        """
        DBì—ì„œ í™œì„± ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•˜ê³  í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        Returns:
            {model_id: {"name": "...", "provider": "...", "model_identifier": "...", "client": OpenAI(...)}}
        """
        db = SessionLocal()
        try:
            models = db.query(Model).filter(Model.is_active == True).all()
            result = {}

            for model in models:
                client = self._create_client_for_model(model.provider)
                result[model.id] = {
                    "name": model.name,
                    "provider": model.provider,
                    "model_identifier": model.model_identifier,
                    "client": client,
                    "description": model.description,
                }
                logger.info(f"  ğŸ“Š Model loaded: {model.name} ({model.provider}/{model.model_identifier})")

            return result

        except Exception as e:
            logger.error(f"í™œì„± ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
        finally:
            db.close()

    def _create_client_for_model(self, provider: str) -> OpenAI:
        """í”„ë¡œë°”ì´ë”ë³„ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        if provider == "openrouter":
            return OpenAI(
                api_key=settings.OPENROUTER_API_KEY,
                base_url="https://openrouter.ai/api/v1",
                default_headers={
                    "HTTP-Referer": "https://craveny.ai",
                    "X-Title": "Craveny Multi-Model Predictor",
                }
            )
        else:  # openai
            return OpenAI(api_key=settings.OPENAI_API_KEY)

    def _predict_with_model(
        self,
        model_id: int,
        model_info: Dict[str, Any],
        prompt: str,
        similar_count: int,
    ) -> Dict[str, Any]:
        """
        íŠ¹ì • ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰

        Args:
            model_id: ëª¨ë¸ ID
            model_info: ëª¨ë¸ ì •ë³´ (client, provider, model_identifier í¬í•¨)
            prompt: ì˜ˆì¸¡ í”„ë¡¬í”„íŠ¸
            similar_count: ìœ ì‚¬ ë‰´ìŠ¤ ê°œìˆ˜

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            client = model_info["client"]
            model_identifier = model_info["model_identifier"]
            provider = model_info["provider"]

            # LLM í˜¸ì¶œ
            if provider == "openrouter":
                response = client.chat.completions.create(
                    model=model_identifier,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1000,
                )
            else:  # openai
                response = client.chat.completions.create(
                    model=model_identifier,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ì„ í†µí•´ ì£¼ê°€ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,
                    max_tokens=1000,
                    response_format={"type": "json_object"},
                )

            # ì‘ë‹µ íŒŒì‹±
            result_text = response.choices[0].message.content

            # OpenRouter ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ
            if provider == "openrouter" and "```json" in result_text:
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', result_text, re.DOTALL)
                if json_match:
                    result_text = json_match.group(1)

            result = json.loads(result_text)

            # ê²°ê³¼ ë³´ê°•
            result["similar_count"] = similar_count
            result["model"] = model_info["name"]
            result["model_id"] = model_id
            result["provider"] = provider
            result["timestamp"] = datetime.now().isoformat()

            # í•˜ìœ„ í˜¸í™˜ì„± ì²˜ë¦¬
            if "confidence_breakdown" not in result:
                result["confidence_breakdown"] = {
                    "similar_news_quality": result.get("confidence", 0),
                    "pattern_consistency": 0,
                    "disclosure_impact": 0,
                    "explanation": "êµ¬ ë²„ì „ ì‘ë‹µ"
                }
            if "pattern_analysis" not in result:
                result["pattern_analysis"] = {
                    "avg_1d": None,
                    "avg_3d": None,
                    "avg_5d": None,
                }

            return result

        except Exception as e:
            logger.error(f"ëª¨ë¸ {model_info['name']} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return {
                "prediction": "ìœ ì§€",
                "confidence": 0,
                "reasoning": f"ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}",
                "short_term": "ì˜ˆì¸¡ ë¶ˆê°€",
                "medium_term": "ì˜ˆì¸¡ ë¶ˆê°€",
                "long_term": "ì˜ˆì¸¡ ë¶ˆê°€",
                "similar_count": similar_count,
                "model": model_info["name"],
                "model_id": model_id,
                "provider": model_info["provider"],
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
            }

    def _save_model_prediction(
        self,
        news_id: int,
        model_id: int,
        stock_code: str,
        prediction_data: Dict[str, Any]
    ) -> None:
        """
        ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            news_id: ë‰´ìŠ¤ ID
            model_id: ëª¨ë¸ ID
            stock_code: ì¢…ëª© ì½”ë“œ
            prediction_data: ì˜ˆì¸¡ ê²°ê³¼
        """
        db = SessionLocal()
        try:
            # UPSERT (INSERT ... ON CONFLICT UPDATE)
            db.execute(
                text("""
                    INSERT INTO model_predictions (news_id, model_id, stock_code, prediction_data)
                    VALUES (:news_id, :model_id, :stock_code, :prediction_data)
                    ON CONFLICT (news_id, model_id)
                    DO UPDATE SET
                        prediction_data = EXCLUDED.prediction_data,
                        created_at = NOW()
                """),
                {
                    "news_id": news_id,
                    "model_id": model_id,
                    "stock_code": stock_code,
                    "prediction_data": json.dumps(prediction_data, ensure_ascii=False),
                }
            )
            db.commit()
            logger.info(f"âœ… ëª¨ë¸ {model_id} ì˜ˆì¸¡ ì €ì¥ ì™„ë£Œ: news_id={news_id}")

        except Exception as e:
            logger.error(f"ëª¨ë¸ ì˜ˆì¸¡ ì €ì¥ ì‹¤íŒ¨: {e}")
            db.rollback()
        finally:
            db.close()

    def _get_prediction_from_db(
        self,
        news_id: int,
        model_id: int
    ) -> Optional[Dict[str, Any]]:
        """
        DBì—ì„œ íŠ¹ì • ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            news_id: ë‰´ìŠ¤ ID
            model_id: ëª¨ë¸ ID

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë˜ëŠ” None
        """
        db = SessionLocal()
        try:
            result = db.execute(
                text("""
                    SELECT prediction_data
                    FROM model_predictions
                    WHERE news_id = :news_id AND model_id = :model_id
                """),
                {"news_id": news_id, "model_id": model_id}
            ).fetchone()

            if result:
                return json.loads(result[0])
            return None

        except Exception as e:
            logger.error(f"ëª¨ë¸ ì˜ˆì¸¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            db.close()

    def _get_active_ab_config(self) -> Optional[ABTestConfig]:
        """í˜„ì¬ í™œì„±í™”ëœ A/B ì„¤ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        db = SessionLocal()
        try:
            config = db.query(ABTestConfig).filter(ABTestConfig.is_active == True).first()
            return config
        except Exception as e:
            logger.error(f"A/B ì„¤ì • ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            db.close()

    def predict_all_models(
        self,
        current_news: Dict[str, Any],
        similar_news: List[Dict[str, Any]],
        news_id: int,
        prompt: str
    ) -> Dict[int, Dict[str, Any]]:
        """
        ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìƒì„±í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            current_news: í˜„ì¬ ë‰´ìŠ¤ ì •ë³´
            similar_news: ìœ ì‚¬ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            news_id: ë‰´ìŠ¤ ID
            prompt: ì˜ˆì¸¡ í”„ë¡¬í”„íŠ¸

        Returns:
            {model_id: prediction_result, ...}
        """
        stock_code = current_news.get("stock_code")
        similar_count = len(similar_news)
        results = {}

        logger.info(f"ğŸ”¬ ëª¨ë“  í™œì„± ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì‹œì‘: news_id={news_id}, models={len(self.active_models)}")

        for model_id, model_info in self.active_models.items():
            logger.info(f"  ğŸ“Š {model_info['name']} ì˜ˆì¸¡ ì¤‘...")

            # ì˜ˆì¸¡ ì‹¤í–‰
            prediction = self._predict_with_model(
                model_id,
                model_info,
                prompt,
                similar_count
            )

            # DB ì €ì¥
            self._save_model_prediction(news_id, model_id, stock_code, prediction)

            results[model_id] = prediction

        logger.info(f"âœ… ëª¨ë“  ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ")
        return results

    def get_ab_predictions(self, news_id: int) -> Dict[str, Any]:
        """
        í˜„ì¬ A/B ì„¤ì •ì— ë”°ë¼ ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            news_id: ë‰´ìŠ¤ ID

        Returns:
            {
                "model_a": {...},
                "model_b": {...},
                "comparison": {...}
            }
        """
        # í™œì„± A/B ì„¤ì • ì¡°íšŒ
        ab_config = self._get_active_ab_config()
        if not ab_config:
            logger.warning("í™œì„± A/B ì„¤ì • ì—†ìŒ")
            return {
                "error": "í™œì„± A/B ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤",
                "model_a": None,
                "model_b": None,
            }

        # ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì¡°íšŒ
        pred_a = self._get_prediction_from_db(news_id, ab_config.model_a_id)
        pred_b = self._get_prediction_from_db(news_id, ab_config.model_b_id)

        if not pred_a or not pred_b:
            logger.warning(f"ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ: model_a={pred_a is not None}, model_b={pred_b is not None}")
            return {
                "error": "ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤",
                "model_a": pred_a,
                "model_b": pred_b,
            }

        # ë¹„êµ ë¶„ì„
        comparison = {
            "agreement": pred_a.get("prediction") == pred_b.get("prediction"),
            "confidence_diff": abs(pred_a.get("confidence", 0) - pred_b.get("confidence", 0)),
            "stronger_model": "model_a" if pred_a.get("confidence", 0) > pred_b.get("confidence", 0) else "model_b",
            "prediction_match": pred_a.get("prediction") == pred_b.get("prediction"),
        }

        return {
            "model_a": pred_a,
            "model_b": pred_b,
            "comparison": comparison,
            "timestamp": datetime.now().isoformat(),
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_multi_predictor: Optional[MultiModelPredictor] = None


def get_multi_predictor() -> MultiModelPredictor:
    """
    MultiModelPredictor ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        MultiModelPredictor ì¸ìŠ¤í„´ìŠ¤
    """
    global _multi_predictor
    if _multi_predictor is None:
        _multi_predictor = MultiModelPredictor()
    return _multi_predictor
