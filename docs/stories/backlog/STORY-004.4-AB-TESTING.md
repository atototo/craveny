# Story 004.4: A/B í…ŒìŠ¤íŠ¸ ë° ì •í™•ë„ ê²€ì¦

**Epic**: Epic 004 | **Priority**: â­â­â­â­ | **Effort**: 5-7ì¼ | **Dependencies**: Story 004.3

---

## ğŸ“‹ Overview

ê¸°ì¡´ ì‹œìŠ¤í…œ(ë‰´ìŠ¤+ì£¼ê°€) vs ì‹ ê·œ ì‹œìŠ¤í…œ(ë‰´ìŠ¤+ì£¼ê°€+íˆ¬ìì+ì¬ë¬´)ë¥¼ A/B í…ŒìŠ¤íŠ¸í•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ ê°œì„  íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.

**ëª©í‘œ**: ë°©í–¥ ì •í™•ë„ +15%p ì´ìƒ, MAE -20% ì´ìƒ

---

## ğŸ¯ Acceptance Criteria

1. âœ… A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ì„¤ê³„
2. âœ… 200ê±´ ë‰´ìŠ¤ ìƒ˜í”Œ ì¤€ë¹„
3. âœ… ê·¸ë£¹ A/B ë¶„ì„ ì‹¤í–‰
4. âœ… í†µê³„ì  ìœ ì˜ì„± ê²€ì • (p < 0.05)
5. âœ… ê²°ê³¼ ë¦¬í¬íŠ¸ ì‘ì„±
6. âœ… ë°©í–¥ ì •í™•ë„ +15%p, MAE -20% ë‹¬ì„±

---

## ğŸ”§ Implementation

### A/B í…ŒìŠ¤íŠ¸ ì„œë¹„ìŠ¤

```python
# backend/services/ab_test_service.py

class ABTestService:
    async def run_ab_test(
        self,
        news_ids: List[int],
        split: str = "50-50"
    ) -> dict:
        """
        A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰

        Args:
            news_ids: í…ŒìŠ¤íŠ¸í•  ë‰´ìŠ¤ ID ë¦¬ìŠ¤íŠ¸
            split: ë¶„í•  ë¹„ìœ¨ (ê¸°ë³¸: 50-50)

        Returns:
            {
                "group_a": [...],  # ê¸°ì¡´ ì‹œìŠ¤í…œ
                "group_b": [...],  # ì‹ ê·œ ì‹œìŠ¤í…œ
                "metrics": {...}
            }
        """
        # ê·¸ë£¹ ë¶„í• 
        group_a_ids, group_b_ids = self._split_groups(news_ids, split)

        results = {
            "group_a": [],
            "group_b": []
        }

        # ê·¸ë£¹ A: ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ (ë‰´ìŠ¤ + ì£¼ê°€ë§Œ)
        for news_id in group_a_ids:
            result = await self._analyze_basic(news_id)
            results["group_a"].append(result)

        # ê·¸ë£¹ B: ì‹ ê·œ í”„ë¡¬í”„íŠ¸ (ë‰´ìŠ¤ + ì£¼ê°€ + íˆ¬ìì + ì¬ë¬´)
        for news_id in group_b_ids:
            result = await self._analyze_enhanced(news_id)
            results["group_b"].append(result)

        # ì‹¤ì œ ë³€ë™ë¥  ìˆ˜ì§‘ (T+5ì¼ í›„)
        await self._collect_actual_changes(news_ids)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = self._calculate_metrics(results)

        return {
            **results,
            "metrics": metrics
        }

    def _calculate_metrics(self, results: dict) -> dict:
        """ì •í™•ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""

        metrics_a = self._calculate_group_metrics(results["group_a"])
        metrics_b = self._calculate_group_metrics(results["group_b"])

        # í†µê³„ì  ìœ ì˜ì„± ê²€ì •
        from scipy.stats import ttest_ind

        t_stat, p_value = ttest_ind(
            [r["direction_correct"] for r in results["group_a"]],
            [r["direction_correct"] for r in results["group_b"]]
        )

        return {
            "group_a": metrics_a,
            "group_b": metrics_b,
            "improvement": {
                "direction_accuracy": metrics_b["direction_accuracy"] - metrics_a["direction_accuracy"],
                "mae": ((metrics_a["mae"] - metrics_b["mae"]) / metrics_a["mae"] * 100)  # % ê°ì†Œ
            },
            "statistical_significance": {
                "t_statistic": t_stat,
                "p_value": p_value,
                "is_significant": p_value < 0.05
            }
        }

    def _calculate_group_metrics(self, group_results: List[dict]) -> dict:
        """ê·¸ë£¹ë³„ ë©”íŠ¸ë¦­"""
        direction_correct = sum(1 for r in group_results if r["direction_correct"])
        mae = sum(r["mae"] for r in group_results) / len(group_results)

        return {
            "sample_size": len(group_results),
            "direction_accuracy": direction_correct / len(group_results) * 100,
            "mae": mae,
            "hit_rate": sum(1 for r in group_results if r["within_ci"]) / len(group_results) * 100
        }
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/run_ab_test.py

async def main():
    # ìµœê·¼ 200ê±´ ë‰´ìŠ¤ ìƒ˜í”Œë§
    news_ids = get_recent_news_sample(days=30, sample_size=200)

    logger.info(f"A/B í…ŒìŠ¤íŠ¸ ì‹œì‘: {len(news_ids)}ê±´")

    # A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    ab_service = ABTestService()
    results = await ab_service.run_ab_test(news_ids)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("="*80)

    metrics = results["metrics"]

    print(f"\nê·¸ë£¹ A (ê¸°ì¡´ ì‹œìŠ¤í…œ):")
    print(f"  - ë°©í–¥ ì •í™•ë„: {metrics['group_a']['direction_accuracy']:.2f}%")
    print(f"  - MAE: {metrics['group_a']['mae']:.2f}%")

    print(f"\nê·¸ë£¹ B (ì‹ ê·œ ì‹œìŠ¤í…œ):")
    print(f"  - ë°©í–¥ ì •í™•ë„: {metrics['group_b']['direction_accuracy']:.2f}%")
    print(f"  - MAE: {metrics['group_b']['mae']:.2f}%")

    print(f"\nê°œì„  íš¨ê³¼:")
    print(f"  - ë°©í–¥ ì •í™•ë„: +{metrics['improvement']['direction_accuracy']:.2f}%p")
    print(f"  - MAE: -{metrics['improvement']['mae']:.2f}%")

    print(f"\ní†µê³„ì  ìœ ì˜ì„±:")
    print(f"  - p-value: {metrics['statistical_significance']['p_value']:.4f}")
    print(f"  - ìœ ì˜í•¨: {'âœ… YES' if metrics['statistical_significance']['is_significant'] else 'âŒ NO'}")

    # ë¦¬í¬íŠ¸ ì €ì¥
    save_ab_test_report(results)

    # ìŠ¹ì¸ ê¸°ì¤€ ì²´í¬
    criteria = {
        "ë°©í–¥ ì •í™•ë„ +15%p": metrics['improvement']['direction_accuracy'] >= 15,
        "MAE -20%": metrics['improvement']['mae'] >= 20,
        "p < 0.05": metrics['statistical_significance']['is_significant']
    }

    print("\nìŠ¹ì¸ ê¸°ì¤€:")
    for criterion, passed in criteria.items():
        print(f"  - {criterion}: {'âœ… PASS' if passed else 'âŒ FAIL'}")

    if all(criteria.values()):
        print("\nğŸ‰ ëª¨ë“  ê¸°ì¤€ í†µê³¼! ì‹ ê·œ ì‹œìŠ¤í…œ ë°°í¬ ìŠ¹ì¸.")
    else:
        print("\nâš ï¸  ì¼ë¶€ ê¸°ì¤€ ë¯¸ë‹¬. ì¶”ê°€ ê°œì„  í•„ìš”.")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## ğŸ“Š Expected Results

```
A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼
================================================================================

ê·¸ë£¹ A (ê¸°ì¡´ ì‹œìŠ¤í…œ):
  - ë°©í–¥ ì •í™•ë„: 65.0%
  - MAE: 3.2%

ê·¸ë£¹ B (ì‹ ê·œ ì‹œìŠ¤í…œ):
  - ë°©í–¥ ì •í™•ë„: 82.0%
  - MAE: 2.1%

ê°œì„  íš¨ê³¼:
  - ë°©í–¥ ì •í™•ë„: +17.0%p
  - MAE: -34.4%

í†µê³„ì  ìœ ì˜ì„±:
  - p-value: 0.0028
  - ìœ ì˜í•¨: âœ… YES

ìŠ¹ì¸ ê¸°ì¤€:
  - ë°©í–¥ ì •í™•ë„ +15%p: âœ… PASS
  - MAE -20%: âœ… PASS
  - p < 0.05: âœ… PASS

ğŸ‰ ëª¨ë“  ê¸°ì¤€ í†µê³¼! ì‹ ê·œ ì‹œìŠ¤í…œ ë°°í¬ ìŠ¹ì¸.
```

---

## âœ… Definition of Done

- [ ] ABTestService êµ¬í˜„
- [ ] 200ê±´ ë‰´ìŠ¤ ìƒ˜í”Œ ì¤€ë¹„
- [ ] A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰
- [ ] ê²°ê³¼ ë¦¬í¬íŠ¸ ì‘ì„± (`docs/reports/ab_test_results.md`)
- [ ] ë°©í–¥ ì •í™•ë„ +15%p ë‹¬ì„±
- [ ] MAE -20% ë‹¬ì„±
- [ ] p < 0.05 í™•ì¸
- [ ] ì½”ë“œ ë¦¬ë·° ë° ë¨¸ì§€
